{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c137f828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02798d08",
   "metadata": {},
   "source": [
    "# Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15037384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['saint_bernard_188.jpg', 'Ragdoll_164.jpg', 'chihuahua_75.jpg', 'american_bulldog_60.jpg', 'Siamese_9.jpg', 'saint_bernard_122.jpg', 'Bombay_95.jpg', 'Bengal_167.jpg', 'Birman_95.jpg', 'havanese_147.jpg']\n",
      "\n",
      "7390\n"
     ]
    }
   ],
   "source": [
    "list_images = []\n",
    "\n",
    "with open('annotations_aug/images_list_orig.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        name = line[:-1]\n",
    "        list_images.append(name)\n",
    "        \n",
    "print(list_images[:10])\n",
    "print()\n",
    "print(len(list_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c28abc2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File name</th>\n",
       "      <th>Class id</th>\n",
       "      <th>Species id</th>\n",
       "      <th>Breed id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abyssinian_100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abyssinian_101</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abyssinian_102</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abyssinian_103</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abyssinian_104</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7344</th>\n",
       "      <td>yorkshire_terrier_96</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7345</th>\n",
       "      <td>yorkshire_terrier_97</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7346</th>\n",
       "      <td>yorkshire_terrier_98</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7347</th>\n",
       "      <td>yorkshire_terrier_99</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7348</th>\n",
       "      <td>yorkshire_terrier_9</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7349 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 File name  Class id  Species id  Breed id\n",
       "0           Abyssinian_100         1           1         1\n",
       "1           Abyssinian_101         1           1         1\n",
       "2           Abyssinian_102         1           1         1\n",
       "3           Abyssinian_103         1           1         1\n",
       "4           Abyssinian_104         1           1         1\n",
       "...                    ...       ...         ...       ...\n",
       "7344  yorkshire_terrier_96        37           2        25\n",
       "7345  yorkshire_terrier_97        37           2        25\n",
       "7346  yorkshire_terrier_98        37           2        25\n",
       "7347  yorkshire_terrier_99        37           2        25\n",
       "7348   yorkshire_terrier_9        37           2        25\n",
       "\n",
       "[7349 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_to_list = 'annotations/list.txt'\n",
    "\n",
    "annotations_df = pd.read_csv(path_to_list, sep=\" \", header=None, skiprows=6, names=[\"File name\", \"Class id\", \"Species id\", \"Breed id\"])\n",
    "\n",
    "display(annotations_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d1cbc7",
   "metadata": {},
   "source": [
    "The list of annotations above is missing some images as there are 7390 images in total in the images folder. So we'll read the filenames from the images directory and make a more complete annotations_df. But first we want a dictionary relating the species and breed name to the (class id,species id,breed id)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffac500",
   "metadata": {},
   "source": [
    "First we define a function that will take the file name and output the corresponding Species:breed. The file names are of the following format: breed_number.ext with the first letter being in upper case for cats and lower case for dogs. For example, the file name of an image of an Abyssinian cat is like 'Abyssinian_34.jpg' (or .png or .gif) and we want the output to be 'Cat: abyssinian'. Similarly the file name for an image of a Beagle dog is like 'beagle_26.jpg' and we want the output to be 'Dog: beagle'.  \n",
    "\n",
    "Later when we augment the training set, we'll name the edited images as 'name_am.jpg' and 'name_ca.jpg' where 'name' is the original name. So we'll design the format_name function to work on such file names as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab484581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat: abyssinian\n",
      "\n",
      "Cat: abyssinian\n",
      "\n",
      "Cat: abyssinian\n"
     ]
    }
   ],
   "source": [
    "def cat_or_dog(inp):       # inp is supposed to be the file (breed) name minus the numbers, _, and the extension.\n",
    "    if inp[0].isupper():\n",
    "        return 'Cat: '+ inp.lower()\n",
    "    else:\n",
    "        return 'Dog: '+ inp\n",
    "\n",
    "def format_name(inp):\n",
    "    inp = os.path.splitext(inp)[0]\n",
    "    out = re.sub('_',' ',inp)\n",
    "    out = re.sub(r'[0-9]+','',out)\n",
    "    \n",
    "    if inp.endswith('am'):\n",
    "        out = out[:-4]\n",
    "    elif inp.endswith('ca'):\n",
    "        out = out[:-4]\n",
    "    else:\n",
    "        out = out[:-1]\n",
    "    \n",
    "    return cat_or_dog(out)\n",
    "\n",
    "print(format_name('Abyssinian_100.png'))\n",
    "print()\n",
    "print(format_name('Abyssinian_93_am.jpg'))\n",
    "print()\n",
    "print(format_name('Abyssinian_27_ca.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c99e1cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cat: abyssinian': (1, 1, 1),\n",
       " 'Dog: american bulldog': (2, 2, 1),\n",
       " 'Dog: american pit bull terrier': (3, 2, 2),\n",
       " 'Dog: basset hound': (4, 2, 3),\n",
       " 'Dog: beagle': (5, 2, 4),\n",
       " 'Cat: bengal': (6, 1, 2),\n",
       " 'Cat: birman': (7, 1, 3),\n",
       " 'Cat: bombay': (8, 1, 4),\n",
       " 'Dog: boxer': (9, 2, 5),\n",
       " 'Cat: british shorthair': (10, 1, 5),\n",
       " 'Dog: chihuahua': (11, 2, 6),\n",
       " 'Cat: egyptian mau': (12, 1, 6),\n",
       " 'Dog: english cocker spaniel': (13, 2, 7),\n",
       " 'Dog: english setter': (14, 2, 8),\n",
       " 'Dog: german shorthaired': (15, 2, 9),\n",
       " 'Dog: great pyrenees': (16, 2, 10),\n",
       " 'Dog: havanese': (17, 2, 11),\n",
       " 'Dog: japanese chin': (18, 2, 12),\n",
       " 'Dog: keeshond': (19, 2, 13),\n",
       " 'Dog: leonberger': (20, 2, 14),\n",
       " 'Cat: maine coon': (21, 1, 7),\n",
       " 'Dog: miniature pinscher': (22, 2, 15),\n",
       " 'Dog: newfoundland': (23, 2, 16),\n",
       " 'Cat: persian': (24, 1, 8),\n",
       " 'Dog: pomeranian': (25, 2, 17),\n",
       " 'Dog: pug': (26, 2, 18),\n",
       " 'Cat: ragdoll': (27, 1, 9),\n",
       " 'Cat: russian blue': (28, 1, 10),\n",
       " 'Dog: saint bernard': (29, 2, 19),\n",
       " 'Dog: samoyed': (30, 2, 20),\n",
       " 'Dog: scottish terrier': (31, 2, 21),\n",
       " 'Dog: shiba inu': (32, 2, 22),\n",
       " 'Cat: siamese': (33, 1, 11),\n",
       " 'Cat: sphynx': (34, 1, 12),\n",
       " 'Dog: staffordshire bull terrier': (35, 2, 23),\n",
       " 'Dog: wheaten terrier': (36, 2, 24),\n",
       " 'Dog: yorkshire terrier': (37, 2, 25)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_dict = {}\n",
    "for i in range(len(annotations_df)):\n",
    "    if format_name(annotations_df.iloc[i,0]) not in annotations_dict:\n",
    "        annotations_dict[format_name(annotations_df.iloc[i,0])] = tuple(annotations_df.iloc[i,1:])\n",
    "annotations_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9d20a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class return_annotations():\n",
    "    def __init__(self,collection):\n",
    "        self.collection = collection\n",
    "        self.names = list(map(lambda x:format_name(x),self.collection))\n",
    "        self.class_ids = [annotations_dict[pet][0] for pet in self.names]\n",
    "        self.species_ids = [annotations_dict[pet][1] for pet in self.names]\n",
    "        self.breed_ids = [annotations_dict[pet][2] for pet in self.names]\n",
    "        \n",
    "    def create_df(self):\n",
    "        return pd.DataFrame({'Image file':self.collection,'Pet':self.names,'Class id':self.class_ids,'Species id':self.species_ids,'Breed id':self.breed_ids})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d991a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "avoid_trimaps = []\n",
    "\n",
    "with open('annotations_aug/avoid_trimaps.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        name = line[:-1]\n",
    "        avoid_trimaps.append(name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b09513",
   "metadata": {},
   "source": [
    "# Original + alpha matted: Train:valid:test = 70:15:15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75608c4",
   "metadata": {},
   "source": [
    "We have 7390 images (before augmentation). Now we'll make a random split of the images into three sets: train, validation, test, in the ratio 3:1:1 approximately.  We don't want any of the newly created images in the validation or test set. Afterwards we'll add some of the augmented images the train data set to create several data sets with different proportions of original and edited images, aiming to achieve the train:valid:test ratio mentioned above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f1d682",
   "metadata": {},
   "source": [
    "Here below and later as well, we'll often fix the random seed so we get the same results when the code is run again. To really ensure pseudorandomness however, we shouldn't do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ecfe1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set has 4449 images which is 60.20 % of the dataset.\n",
      "The validation set has 1491 images which is 20.18 % of the dataset.\n",
      "The test set has 1450 images which is 19.62 % of the dataset.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "images_train = []\n",
    "images_valid = []\n",
    "images_test = []\n",
    "for img in list_images:\n",
    "    choice = np.random.choice([1,2,3],p=[0.6,0.2,0.2])  \n",
    "    if choice == 1:\n",
    "        images_train.append(img)\n",
    "    elif choice == 2:\n",
    "        images_valid.append(img)\n",
    "    elif choice == 3:\n",
    "        images_test.append(img)\n",
    "        \n",
    "\n",
    "print('The training set has {} images which is {:.2f} % of the dataset.'.format(len(images_train),100*(len(images_train)/len(list_images))))\n",
    "print('The validation set has {} images which is {:.2f} % of the dataset.'.format(len(images_valid),100*(len(images_valid)/len(list_images))))\n",
    "print('The test set has {} images which is {:.2f} % of the dataset.'.format(len(images_test),100*(len(images_test)/len(list_images))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac7a8d9",
   "metadata": {},
   "source": [
    "Now we'll prepare a dataframe with the annotations for each of these three sets of images. We'll do it by defining a class with some attributes carrying the different annotations, and a method to return the df organising all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bda7ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "      \n",
    "annot_train = return_annotations(images_train)\n",
    "annot_valid = return_annotations(images_valid)\n",
    "annot_test = return_annotations(images_test)\n",
    "\n",
    "annot_train_df = annot_train.create_df()\n",
    "annot_valid_df = annot_valid.create_df()\n",
    "annot_test_df = annot_test.create_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfa91ee",
   "metadata": {},
   "source": [
    "Let us export the validation and test dataframes as csv files. We'll still be modifying the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87279dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_valid_df.to_csv('annotations_aug/annotations_valid.csv',index=False)\n",
    "annot_test_df.to_csv('annotations_aug/annotations_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08da0e9f",
   "metadata": {},
   "source": [
    "### Three augmented training sets (original + alpha matted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb5509a",
   "metadata": {},
   "source": [
    "We started out with roughly $200$ images per class, we moved about $40$ of each into the validation set, about another $40$ into the test set, and we augmented the remaining $120$ to create roughly $240$ images per class. We'll try to have about $190$ images per class in the training dataset, so we have approximately a $70:15:15$ train:valid:test ration. We'll make three different datasets wherein we'll make up the $190$ images per class from the original and the edited images in different proportions. \n",
    "\n",
    "We can think of this ratio of original to edited images as another hyperparameter. We'll go for $r_1= 60:40$, $r_2=50:50$, and $r_3=40:60$. For the set $i$, the number of original images included should be about $\\frac{190 r_i}{1+r_i}$ and the number of edited ones about $\\frac{190}{1+ r_i}$. Therefore each of the original images in the training should have a $\\frac{19 r_i}{12(1+r_i)}$ chance of getting into the training set, and each edited image should have a $\\frac{19}{12(1+r_i)}$ chance.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d203f2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_set(r):\n",
    "    t_set = []\n",
    "    for img in annot_train_df['Image file']:\n",
    "        if np.random.choice([True,False],p=[(19*r)/(12*(1+r)),1-((19*r)/(12*(1+r)))]):\n",
    "            t_set.append(img)\n",
    "        if os.path.splitext(img)[0] not in avoid_trimaps:\n",
    "            if np.random.choice([True,False],p=[19/(12*(1+r)),1-(19/(12*(1+r)))]):\n",
    "                t_set.append(os.path.splitext(img)[0]+'_am.jpg')\n",
    "            \n",
    "    t_annot = return_annotations(t_set)\n",
    "    return t_annot.create_df()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8a91d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "train_r1_df = create_train_set(1.5)\n",
    "train_r1_df.to_csv('annotations_aug/annotations_train_r1.csv',index=False)\n",
    "\n",
    "np.random.seed(20000)\n",
    "train_r2_df = create_train_set(1)\n",
    "train_r2_df.to_csv('annotations_aug/annotations_train_r2.csv',index=False)\n",
    "\n",
    "np.random.seed(50000)\n",
    "train_r3_df = create_train_set(2/3)\n",
    "train_r3_df.to_csv('annotations_aug/annotations_train_r3.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d46497",
   "metadata": {},
   "source": [
    "Now let's get summarize the datasets available to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ef3cfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(train_df): \n",
    "    \n",
    "    len_train = len(train_df)\n",
    "    len_valid = len(images_valid)\n",
    "    len_test = len(images_test)\n",
    "    total = len_train + len_valid + len_test\n",
    "    \n",
    "    number_edited = sum([os.path.splitext(file)[0].endswith('am') for file in train_df['Image file']])\n",
    "    number_original = len_train - number_edited\n",
    "    \n",
    "    print('There are {}, {}, and {} images in the training, validation, and test sets, respectively.'.format(len_train, len_valid, len_test))\n",
    "    print()\n",
    "    print('The train:valid:test ratio is roughly {:.2f}:{:.2f}:{:.2f}.'.format(len_train*100/total, len_valid*100/total, len_test*100/total))\n",
    "    print()\n",
    "    print('The ratio of original images to the edited ones is about {:.2f}:{:.2f}.'.format(number_original*100/len_train,number_edited*100/len_train))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a4b3fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7109, 1491, and 1450 images in the training, validation, and test sets, respectively.\n",
      "\n",
      "The train:valid:test ratio is roughly 70.74:14.84:14.43.\n",
      "\n",
      "The ratio of original images to the edited ones is about 59.46:40.54.\n"
     ]
    }
   ],
   "source": [
    "summarize(train_r1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92bd65be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6983, 1491, and 1450 images in the training, validation, and test sets, respectively.\n",
      "\n",
      "The train:valid:test ratio is roughly 70.36:15.02:14.61.\n",
      "\n",
      "The ratio of original images to the edited ones is about 50.49:49.51.\n"
     ]
    }
   ],
   "source": [
    "summarize(train_r2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37650f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7102, 1491, and 1450 images in the training, validation, and test sets, respectively.\n",
      "\n",
      "The train:valid:test ratio is roughly 70.72:14.85:14.44.\n",
      "\n",
      "The ratio of original images to the edited ones is about 40.78:59.22.\n"
     ]
    }
   ],
   "source": [
    "summarize(train_r3_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8472849",
   "metadata": {},
   "source": [
    "Let's also create another training dataset without rejecting any of the images available in the training set in annot_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c691832e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8885, 1491, and 1450 images in the training, validation, and test sets, respectively.\n",
      "\n",
      "The train:valid:test ratio is roughly 75.13:12.61:12.26.\n",
      "\n",
      "The ratio of original images to the edited ones is about 50.07:49.93.\n"
     ]
    }
   ],
   "source": [
    "t_larger_set = []\n",
    "for img in annot_train_df['Image file']:\n",
    "    t_larger_set.append(img)\n",
    "    if os.path.splitext(img)[0] not in avoid_trimaps:\n",
    "        t_larger_set.append(os.path.splitext(img)[0]+'_am.jpg')\n",
    "            \n",
    "t_larger_annot = return_annotations(t_larger_set)\n",
    "t_larger_annot_df = t_larger_annot.create_df()\n",
    "\n",
    "t_larger_annot_df.to_csv('annotations_aug/annotations_train_240approx.csv',index=False)\n",
    "\n",
    "summarize(t_larger_annot_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a78a97",
   "metadata": {},
   "source": [
    "# Original + alpha matted: Larger training sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbfe59d",
   "metadata": {},
   "source": [
    "The training sets above seem to be inadequate for the models to learn to distinguish between different breeds (this is reasonable as different breeds in the same species are largely similar). So we will create some datasets with larger training sets and smaller validation and test sets and see if the performance is improved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d6e98c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set has 5940 images which is 80.38 % of the dataset.\n",
      "The validation set has 919 images which is 12.44 % of the dataset.\n",
      "The test set has 531 images which is 7.19 % of the dataset.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "imgL_train = []\n",
    "imgL_valid = []\n",
    "imgL_test = []\n",
    "for img in list_images:\n",
    "    choice = np.random.choice([1,2,3],p=[0.8,0.125,0.075])  \n",
    "    if choice == 1:\n",
    "        imgL_train.append(img)\n",
    "    elif choice == 2:\n",
    "        imgL_valid.append(img)\n",
    "    elif choice == 3:\n",
    "        imgL_test.append(img)\n",
    "        \n",
    "\n",
    "print('The training set has {} images which is {:.2f} % of the dataset.'.format(len(imgL_train),100*(len(imgL_train)/len(list_images))))\n",
    "print('The validation set has {} images which is {:.2f} % of the dataset.'.format(len(imgL_valid),100*(len(imgL_valid)/len(list_images))))\n",
    "print('The test set has {} images which is {:.2f} % of the dataset.'.format(len(imgL_test),100*(len(imgL_test)/len(list_images))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1cf2b75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotL_train = return_annotations(imgL_train)\n",
    "annotL_valid = return_annotations(imgL_valid)\n",
    "annotL_test = return_annotations(imgL_test)\n",
    "\n",
    "annotL_train_df = annotL_train.create_df()\n",
    "annotL_valid_df = annotL_valid.create_df()\n",
    "annotL_test_df = annotL_test.create_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e0c5eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotL_valid_df.to_csv('annotations_aug/annotations_valid_L.csv',index=False)\n",
    "annotL_test_df.to_csv('annotations_aug/annotations_test_L.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "987aeecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_set_Lall = []\n",
    "for img in annotL_train_df['Image file']:\n",
    "    t_set_Lall.append(img)\n",
    "    if os.path.splitext(img)[0] not in avoid_trimaps:\n",
    "        t_set_Lall.append(os.path.splitext(img)[0]+'_am.jpg')\n",
    "            \n",
    "train_Lall = return_annotations(t_set_Lall)\n",
    "train_Lall_df = train_Lall.create_df() \n",
    "train_Lall_df.to_csv('annotations_aug/annotations_train_Lall.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "edddd281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarizeL(train_df): \n",
    "    \n",
    "    len_train = len(train_df)\n",
    "    len_valid = len(imgL_valid)\n",
    "    len_test = len(imgL_test)\n",
    "    total = len_train + len_valid + len_test\n",
    "    \n",
    "    number_edited = sum([os.path.splitext(file)[0].endswith('am') for file in train_df['Image file']])\n",
    "    number_original = len_train - number_edited\n",
    "    \n",
    "    print('There are {}, {}, and {} images in the training, validation, and test sets, respectively.'.format(len_train, len_valid, len_test))\n",
    "    print()\n",
    "    print('The train:valid:test ratio is roughly {:.2f}:{:.2f}:{:.2f}.'.format(len_train*100/total, len_valid*100/total, len_test*100/total))\n",
    "    print()\n",
    "    print('The ratio of original images to the edited ones is about {:.2f}:{:.2f}.'.format(number_original*100/len_train,number_edited*100/len_train))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4b4bb637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 11860, 919, and 531 images in the training, validation, and test sets, respectively.\n",
      "\n",
      "The train:valid:test ratio is roughly 89.11:6.90:3.99.\n",
      "\n",
      "The ratio of original images to the edited ones is about 50.08:49.92.\n"
     ]
    }
   ],
   "source": [
    "summarizeL(train_Lall_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb0cbb5",
   "metadata": {},
   "source": [
    "# No augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2925ce94",
   "metadata": {},
   "source": [
    "We'll carry out some experiments based on the original images alone (after resizing to a uniform shape and size). So we'll prepare a dataset with roughly 180 images/per class in the training set, 12 images/class in the dev set, and 8 images/class in the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d961076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set has 6308 images which is 85.36 % of the dataset.\n",
      "The validation set has 720 images which is 9.74 % of the dataset.\n",
      "The test set has 362 images which is 4.90 % of the dataset.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1359)\n",
    "\n",
    "imgO_train = []\n",
    "imgO_valid = []\n",
    "imgO_test = []\n",
    "for img in list_images:\n",
    "    choice = np.random.choice([1,2,3],p=[0.85,0.1,0.05])  \n",
    "    if choice == 1:\n",
    "        imgO_train.append(img)\n",
    "    elif choice == 2:\n",
    "        imgO_valid.append(img)\n",
    "    elif choice == 3:\n",
    "        imgO_test.append(img)\n",
    "        \n",
    "\n",
    "print('The training set has {} images which is {:.2f} % of the dataset.'.format(len(imgO_train),100*(len(imgO_train)/len(list_images))))\n",
    "print('The validation set has {} images which is {:.2f} % of the dataset.'.format(len(imgO_valid),100*(len(imgO_valid)/len(list_images))))\n",
    "print('The test set has {} images which is {:.2f} % of the dataset.'.format(len(imgO_test),100*(len(imgO_test)/len(list_images))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e32ef999",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotO_train = return_annotations(imgO_train)\n",
    "annotO_valid = return_annotations(imgO_valid)\n",
    "annotO_test = return_annotations(imgO_test)\n",
    "\n",
    "annotO_train_df = annotO_train.create_df()\n",
    "annotO_valid_df = annotO_valid.create_df()\n",
    "annotO_test_df = annotO_test.create_df()\n",
    "\n",
    "annotO_train_df.to_csv('annotations_aug/annotations_train_O.csv',index=False)\n",
    "annotO_valid_df.to_csv('annotations_aug/annotations_valid_O.csv',index=False)\n",
    "annotO_test_df.to_csv('annotations_aug/annotations_test_O.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be85128a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6308, 720, and 362 images in the training, validation, and test sets, respectively.\n",
      "\n",
      "The train:valid:test ratio is roughly 85.36:9.74:4.90.\n",
      "\n",
      "There are no augmented images in this dataset.\n"
     ]
    }
   ],
   "source": [
    "len_train = len(imgO_train)\n",
    "len_valid = len(imgO_valid)\n",
    "len_test = len(imgO_test)\n",
    "total = len_train + len_valid + len_test\n",
    "    \n",
    "\n",
    "print('There are {}, {}, and {} images in the training, validation, and test sets, respectively.'.format(len_train, len_valid, len_test))\n",
    "print()\n",
    "print('The train:valid:test ratio is roughly {:.2f}:{:.2f}:{:.2f}.'.format(len_train*100/total, len_valid*100/total, len_test*100/total))\n",
    "print()\n",
    "print('There are no augmented images in this dataset.')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8566430",
   "metadata": {},
   "source": [
    "# Original + alpha matted + rotations and projective transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea32061c",
   "metadata": {},
   "source": [
    "We'll make a couple of datasets from the original and two sets of augmented images. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb21fb4",
   "metadata": {},
   "source": [
    "# B1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1920de58",
   "metadata": {},
   "source": [
    "At first we'll take roughly 150 images per class in the training set, 30 in the validation and 20 in the test set. So we have roughly 450 training images per class including the augmented images for each image in the training set, which gives us a train:valid:test ratio of 90:6:4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d5994a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set has 5553 original images which is 75.14 % of the original dataset.\n",
      "The validation set has 1117 images which is 15.12 % of the original dataset.\n",
      "The test set has 720 images which is 9.74 % of the original dataset.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(14)\n",
    "\n",
    "images_train = []\n",
    "images_valid = []\n",
    "images_test = []\n",
    "for img in list_images:\n",
    "    choice = np.random.choice([1,2,3],p=[0.75,0.15,0.1])  \n",
    "    if choice == 1:\n",
    "        images_train.append(img)\n",
    "    elif choice == 2:\n",
    "        images_valid.append(img)\n",
    "    elif choice == 3:\n",
    "        images_test.append(img)\n",
    "        \n",
    "        \n",
    "print('The training set has {} original images which is {:.2f} % of the original dataset.'.format(len(images_train),100*(len(images_train)/len(list_images))))\n",
    "print('The validation set has {} images which is {:.2f} % of the original dataset.'.format(len(images_valid),100*(len(images_valid)/len(list_images))))\n",
    "print('The test set has {} images which is {:.2f} % of the original dataset.'.format(len(images_test),100*(len(images_test)/len(list_images))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c64a8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_train = return_annotations(images_train)\n",
    "annot_valid = return_annotations(images_valid)\n",
    "annot_test = return_annotations(images_test)\n",
    "\n",
    "annot_train_df = annot_train.create_df()\n",
    "annot_valid_df = annot_valid.create_df()\n",
    "annot_test_df = annot_test.create_df()\n",
    "\n",
    "annot_valid_df.to_csv('annotations_aug/annotations_valid_B1.csv',index=False)\n",
    "annot_test_df.to_csv('annotations_aug/annotations_test_B1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5271a073",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_set_B1 = []\n",
    "for img in annot_train_df['Image file']:\n",
    "    t_set_B1.append(img)\n",
    "    if os.path.splitext(img)[0] not in avoid_trimaps:\n",
    "        t_set_B1.append(os.path.splitext(img)[0]+'_am.jpg')\n",
    "    t_set_B1.append(os.path.splitext(img)[0]+'_ca.jpg')\n",
    "            \n",
    "train_B1 = return_annotations(t_set_B1)\n",
    "train_B1_df = train_B1.create_df() \n",
    "train_B1_df.to_csv('annotations_aug/annotations_train_B1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba9a95c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 16642, 1117, and 720 images in the training, validation, and test sets, respectively.\n",
      "\n",
      "The train:valid:test ratio is roughly 90.06:6.04:3.90.\n"
     ]
    }
   ],
   "source": [
    "len_train = len(train_B1_df)\n",
    "len_valid = len(images_valid)\n",
    "len_test = len(images_test)\n",
    "total = len_train + len_valid + len_test\n",
    "    \n",
    "\n",
    "print('There are {}, {}, and {} images in the training, validation, and test sets, respectively.'.format(len_train, len_valid, len_test))\n",
    "print()\n",
    "print('The train:valid:test ratio is roughly {:.2f}:{:.2f}:{:.2f}.'.format(len_train*100/total, len_valid*100/total, len_test*100/total))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52eed592",
   "metadata": {},
   "source": [
    "# B2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95839ddb",
   "metadata": {},
   "source": [
    "We'll take roughly 160 images per class in the training set, 25 in the validation and 15 in the test set. So we have roughly 480 training images per class including the augmented images for each image in the training set, which gives us a train:valid:test ratio of 92.3:4.8:2.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0fd744b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set has 5883 original images which is 79.61 % of the original dataset.\n",
      "The validation set has 960 images which is 12.99 % of the original dataset.\n",
      "The test set has 547 images which is 7.40 % of the original dataset.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(14)\n",
    "\n",
    "images_train = []\n",
    "images_valid = []\n",
    "images_test = []\n",
    "for img in list_images:\n",
    "    choice = np.random.choice([1,2,3],p=[0.8,0.125,0.075])  \n",
    "    if choice == 1:\n",
    "        images_train.append(img)\n",
    "    elif choice == 2:\n",
    "        images_valid.append(img)\n",
    "    elif choice == 3:\n",
    "        images_test.append(img)\n",
    "        \n",
    "        \n",
    "print('The training set has {} original images which is {:.2f} % of the original dataset.'.format(len(images_train),100*(len(images_train)/len(list_images))))\n",
    "print('The validation set has {} images which is {:.2f} % of the original dataset.'.format(len(images_valid),100*(len(images_valid)/len(list_images))))\n",
    "print('The test set has {} images which is {:.2f} % of the original dataset.'.format(len(images_test),100*(len(images_test)/len(list_images))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95851513",
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_train = return_annotations(images_train)\n",
    "annot_valid = return_annotations(images_valid)\n",
    "annot_test = return_annotations(images_test)\n",
    "\n",
    "annot_train_df = annot_train.create_df()\n",
    "annot_valid_df = annot_valid.create_df()\n",
    "annot_test_df = annot_test.create_df()\n",
    "\n",
    "annot_valid_df.to_csv('annotations_aug/annotations_valid_B2.csv',index=False)\n",
    "annot_test_df.to_csv('annotations_aug/annotations_test_B2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "088d2314",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_set_B2 = []\n",
    "for img in annot_train_df['Image file']:\n",
    "    t_set_B2.append(img)\n",
    "    if os.path.splitext(img)[0] not in avoid_trimaps:\n",
    "        t_set_B2.append(os.path.splitext(img)[0]+'_am.jpg')\n",
    "    t_set_B2.append(os.path.splitext(img)[0]+'_ca.jpg')\n",
    "            \n",
    "train_B2 = return_annotations(t_set_B2)\n",
    "train_B2_df = train_B2.create_df() \n",
    "train_B2_df.to_csv('annotations_aug/annotations_train_B2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b267a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 17630, 960, and 547 images in the training, validation, and test sets, respectively.\n",
      "\n",
      "The train:valid:test ratio is roughly 92.13:5.02:2.86.\n"
     ]
    }
   ],
   "source": [
    "len_train = len(train_B2_df)\n",
    "len_valid = len(images_valid)\n",
    "len_test = len(images_test)\n",
    "total = len_train + len_valid + len_test\n",
    "    \n",
    "\n",
    "print('There are {}, {}, and {} images in the training, validation, and test sets, respectively.'.format(len_train, len_valid, len_test))\n",
    "print()\n",
    "print('The train:valid:test ratio is roughly {:.2f}:{:.2f}:{:.2f}.'.format(len_train*100/total, len_valid*100/total, len_test*100/total))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b836c42e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
