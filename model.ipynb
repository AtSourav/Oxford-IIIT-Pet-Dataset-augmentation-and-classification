{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a2f04fa",
   "metadata": {},
   "source": [
    "We shall now build and train a Convolutional Neural Network on the augmented Oxford IIIT Pet Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "699a5ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import skimage as ski\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from torchvision import transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc008cd6",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7943f91",
   "metadata": {},
   "source": [
    "We shall use the Dataset class to build a custom dataset class inheriting from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5bc72dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PetDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_annotations = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_annotations)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img_path = os.path.join(self.img_dir,self.img_annotations.iloc[idx,0])\n",
    "        image = ski.io.imread(img_path)/255    # not using read_image coz it can only read jpeg or png\n",
    "        image = image[:,:,:3]  # dropping the alpha channel if any\n",
    "        class_label = self.img_annotations.iloc[idx,2]-1      # the -1 is coz labels are expected from 0 to C-1\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            class_label = self.target_transform(class_label)     \n",
    "        return image, class_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cec6ebe",
   "metadata": {},
   "source": [
    "Let's define the transforms, read_image already reads the images as tensors so we don't need to use ToTensor, we shall only resize the images to (size,size) pixels. We shall use the NLL Loss later, this expects as target a class index ranging from 0 to C-1. So we don't need one-hot encoding for the target, but in principle we could do it as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf35b87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 256\n",
    "resize = T.Resize(size)\n",
    "totensor = T.ToTensor()\n",
    "trans = T.Compose([totensor,resize])     # totensor has to be applied first and then resize coz the latter doesn't work on numpy arrays\n",
    "#label_transform_one_hot = T.Lambda(lambda y: torch.zeros(37, dtype=torch.float).scatter_(dim=0,index=torch.tensor(y),value=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35ebd05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_r1 = PetDataset('annotations_aug/annotations_train_r1.csv','img_augmented_processed/', transform = trans)\n",
    "train_r2 = PetDataset('annotations_aug/annotations_train_r2.csv','img_augmented_processed/', transform = trans)\n",
    "train_r3 = PetDataset('annotations_aug/annotations_train_r3.csv','img_augmented_processed/', transform = trans)\n",
    "valid = PetDataset('annotations_aug/annotations_valid.csv','img_augmented_processed/', transform = trans)\n",
    "test = PetDataset('annotations_aug/annotations_test.csv','img_augmented_processed/', transform = trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2eb04348",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_r1_loader = DataLoader(train_r1,batch_size=64,shuffle=True)\n",
    "train_r2_loader = DataLoader(train_r2,batch_size=64,shuffle=True)\n",
    "train_r3_loader = DataLoader(train_r3,batch_size=64,shuffle=True)\n",
    "valid_loader = DataLoader(valid,batch_size=64,shuffle=True)\n",
    "test_loader = DataLoader(test,batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59450cca",
   "metadata": {},
   "source": [
    "We can call the first batch in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6ff560f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of training batch (images): torch.Size([64, 3, 256, 256])\n",
      "shape of training batch (labels): torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_b1_img, train_b1_label = next(iter(train_r1_loader))\n",
    "print('shape of training batch (images): {}'.format(train_b1_img.shape))\n",
    "print('shape of training batch (labels): {}'.format(train_b1_label.shape))\n",
    "plt.imshow(train_b1_img[np.random.randint(64)].permute(1,2,0))     #plt.imshow needs the shape to be (x,y,3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c74a5c2",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d4d4d8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PetCNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 8, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): MaxPool2d(kernel_size=4, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (dense1): Sequential(\n",
      "    (0): Linear(in_features=125000, out_features=1000, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (dense2): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=37, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class PetCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "                                    nn.Conv2d(in_channels=3, out_channels=8, kernel_size=5),\n",
    "                                    nn.MaxPool2d(kernel_size=4,stride=2),\n",
    "                                    nn.ReLU())\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "                                    nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3),\n",
    "                                    nn.MaxPool2d(kernel_size=4,stride=2),\n",
    "                                    nn.ReLU())\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "                                    nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3),\n",
    "                                    nn.MaxPool2d(kernel_size=4,stride=2),\n",
    "                                    nn.ReLU())\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "                                    nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "                                    nn.MaxPool2d(kernel_size=4,stride=2),\n",
    "                                    nn.BatchNorm2d(64)\n",
    "                                    nn.ReLU())\n",
    "        \n",
    "        self.dense1 = nn.Sequential(\n",
    "                                    nn.Linear(int(64**, 1000),\n",
    "                                    nn.ReLU())\n",
    "        \n",
    "        self.dense2 = nn.Sequential(\n",
    "                                    nn.Linear(1000,37),\n",
    "                                    nn.ReLU())\n",
    "        \n",
    "        #self.dense3 = nn.Sequential(\n",
    "                                    #nn.Linear(200,37))\n",
    "                            \n",
    "            \n",
    "    def forward(self,x):\n",
    "        out = self.conv1(x)\n",
    "        out = out.view(out.size(0),-1)      # reshaping the output shaped (N,C,H,W) from the conv layer to (N,n_inp) for the dense layer\n",
    "        out = self.dense1(out)\n",
    "        out = self.dense2(out)\n",
    "        #out = self.dense3(out)\n",
    "        out = nn.functional.log_softmax(out,dim=1)     #we'll use the NLL loss, so we used the log softmax function as reqd by pytorch \n",
    "        \n",
    "        return out\n",
    "    \n",
    "\n",
    "\n",
    "model = PetCNN()\n",
    "loss_function = nn.NLLLoss()\n",
    "learning_rate = 0.000005\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n",
    "print(model)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "303d9f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.0.weight tensor(9.0081)\n",
      "conv1.0.bias tensor(0.0003)\n",
      "conv1.2.weight tensor(0.0307)\n",
      "conv1.2.bias tensor(0.0404)\n",
      "dense1.0.weight tensor(78755.5938)\n",
      "dense1.0.bias tensor(0.8804)\n",
      "dense2.0.weight tensor(93.6995)\n",
      "dense2.0.bias tensor(0.4006)\n",
      "conv1.0.weight tensor(5.6980)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.0365)\n",
      "conv1.2.bias tensor(0.0520)\n",
      "dense1.0.weight tensor(69706.5312)\n",
      "dense1.0.bias tensor(0.8879)\n",
      "dense2.0.weight tensor(92.0112)\n",
      "dense2.0.bias tensor(0.4276)\n",
      "conv1.0.weight tensor(6.5970)\n",
      "conv1.0.bias tensor(0.0001)\n",
      "conv1.2.weight tensor(0.0806)\n",
      "conv1.2.bias tensor(0.0962)\n",
      "dense1.0.weight tensor(70093.6719)\n",
      "dense1.0.bias tensor(0.8378)\n",
      "dense2.0.weight tensor(96.5360)\n",
      "dense2.0.bias tensor(0.4032)\n",
      "conv1.0.weight tensor(7.1605)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.0891)\n",
      "conv1.2.bias tensor(0.1278)\n",
      "dense1.0.weight tensor(62639.0273)\n",
      "dense1.0.bias tensor(0.8082)\n",
      "dense2.0.weight tensor(86.4849)\n",
      "dense2.0.bias tensor(0.3445)\n",
      "conv1.0.weight tensor(12.0641)\n",
      "conv1.0.bias tensor(8.6179e-05)\n",
      "conv1.2.weight tensor(0.1203)\n",
      "conv1.2.bias tensor(0.1432)\n",
      "dense1.0.weight tensor(60071.5977)\n",
      "dense1.0.bias tensor(0.7408)\n",
      "dense2.0.weight tensor(92.1219)\n",
      "dense2.0.bias tensor(0.3362)\n",
      "conv1.0.weight tensor(4.9366)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.0629)\n",
      "conv1.2.bias tensor(0.0719)\n",
      "dense1.0.weight tensor(64157.3477)\n",
      "dense1.0.bias tensor(0.8391)\n",
      "dense2.0.weight tensor(95.0142)\n",
      "dense2.0.bias tensor(0.3742)\n",
      "conv1.0.weight tensor(7.4559)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.0594)\n",
      "conv1.2.bias tensor(0.0585)\n",
      "dense1.0.weight tensor(59796.7891)\n",
      "dense1.0.bias tensor(0.7409)\n",
      "dense2.0.weight tensor(88.5214)\n",
      "dense2.0.bias tensor(0.3181)\n",
      "conv1.0.weight tensor(5.8983)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.0653)\n",
      "conv1.2.bias tensor(0.0551)\n",
      "dense1.0.weight tensor(61142.5234)\n",
      "dense1.0.bias tensor(0.7138)\n",
      "dense2.0.weight tensor(89.0635)\n",
      "dense2.0.bias tensor(0.2814)\n",
      "conv1.0.weight tensor(11.0773)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.1266)\n",
      "conv1.2.bias tensor(0.1299)\n",
      "dense1.0.weight tensor(62777.6250)\n",
      "dense1.0.bias tensor(0.7219)\n",
      "dense2.0.weight tensor(101.6626)\n",
      "dense2.0.bias tensor(0.3193)\n",
      "conv1.0.weight tensor(6.6810)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.0910)\n",
      "conv1.2.bias tensor(0.0993)\n",
      "dense1.0.weight tensor(52306.5391)\n",
      "dense1.0.bias tensor(0.6358)\n",
      "dense2.0.weight tensor(84.0543)\n",
      "dense2.0.bias tensor(0.3104)\n",
      "conv1.0.weight tensor(5.8468)\n",
      "conv1.0.bias tensor(0.0001)\n",
      "conv1.2.weight tensor(0.0804)\n",
      "conv1.2.bias tensor(0.0897)\n",
      "dense1.0.weight tensor(43281.4141)\n",
      "dense1.0.bias tensor(0.5928)\n",
      "dense2.0.weight tensor(75.4889)\n",
      "dense2.0.bias tensor(0.2835)\n",
      "conv1.0.weight tensor(9.6023)\n",
      "conv1.0.bias tensor(0.0001)\n",
      "conv1.2.weight tensor(0.0624)\n",
      "conv1.2.bias tensor(0.0627)\n",
      "dense1.0.weight tensor(45759.2930)\n",
      "dense1.0.bias tensor(0.5279)\n",
      "dense2.0.weight tensor(59.9075)\n",
      "dense2.0.bias tensor(0.2017)\n",
      "conv1.0.weight tensor(5.2093)\n",
      "conv1.0.bias tensor(0.0001)\n",
      "conv1.2.weight tensor(0.0724)\n",
      "conv1.2.bias tensor(0.0861)\n",
      "dense1.0.weight tensor(48427.3633)\n",
      "dense1.0.bias tensor(0.5400)\n",
      "dense2.0.weight tensor(74.1988)\n",
      "dense2.0.bias tensor(0.2359)\n",
      "conv1.0.weight tensor(12.0951)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.0593)\n",
      "conv1.2.bias tensor(0.0507)\n",
      "dense1.0.weight tensor(52832.1875)\n",
      "dense1.0.bias tensor(0.6809)\n",
      "dense2.0.weight tensor(84.2731)\n",
      "dense2.0.bias tensor(0.3139)\n",
      "conv1.0.weight tensor(3.3912)\n",
      "conv1.0.bias tensor(0.0001)\n",
      "conv1.2.weight tensor(0.1044)\n",
      "conv1.2.bias tensor(0.1107)\n",
      "dense1.0.weight tensor(39179.1484)\n",
      "dense1.0.bias tensor(0.5057)\n",
      "dense2.0.weight tensor(65.3126)\n",
      "dense2.0.bias tensor(0.2204)\n",
      "conv1.0.weight tensor(4.3014)\n",
      "conv1.0.bias tensor(0.0003)\n",
      "conv1.2.weight tensor(0.0910)\n",
      "conv1.2.bias tensor(0.0881)\n",
      "dense1.0.weight tensor(37160.3281)\n",
      "dense1.0.bias tensor(0.5196)\n",
      "dense2.0.weight tensor(64.7018)\n",
      "dense2.0.bias tensor(0.2622)\n",
      "conv1.0.weight tensor(6.1090)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.0574)\n",
      "conv1.2.bias tensor(0.0388)\n",
      "dense1.0.weight tensor(45813.5820)\n",
      "dense1.0.bias tensor(0.5143)\n",
      "dense2.0.weight tensor(67.9808)\n",
      "dense2.0.bias tensor(0.2068)\n",
      "conv1.0.weight tensor(7.3709)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.0384)\n",
      "conv1.2.bias tensor(0.0351)\n",
      "dense1.0.weight tensor(32499.2773)\n",
      "dense1.0.bias tensor(0.3256)\n",
      "dense2.0.weight tensor(48.5461)\n",
      "dense2.0.bias tensor(0.1276)\n",
      "conv1.0.weight tensor(4.1852)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.0220)\n",
      "conv1.2.bias tensor(0.0299)\n",
      "dense1.0.weight tensor(32499.1855)\n",
      "dense1.0.bias tensor(0.3974)\n",
      "dense2.0.weight tensor(53.6350)\n",
      "dense2.0.bias tensor(0.2016)\n",
      "conv1.0.weight tensor(6.9646)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.0584)\n",
      "conv1.2.bias tensor(0.0688)\n",
      "dense1.0.weight tensor(34966.9492)\n",
      "dense1.0.bias tensor(0.4638)\n",
      "dense2.0.weight tensor(50.2464)\n",
      "dense2.0.bias tensor(0.1882)\n",
      "conv1.0.weight tensor(4.1104)\n",
      "conv1.0.bias tensor(0.0003)\n",
      "conv1.2.weight tensor(0.0312)\n",
      "conv1.2.bias tensor(0.0299)\n",
      "dense1.0.weight tensor(33496.8047)\n",
      "dense1.0.bias tensor(0.4352)\n",
      "dense2.0.weight tensor(57.6207)\n",
      "dense2.0.bias tensor(0.2134)\n",
      "conv1.0.weight tensor(7.6833)\n",
      "conv1.0.bias tensor(0.0003)\n",
      "conv1.2.weight tensor(0.0497)\n",
      "conv1.2.bias tensor(0.0802)\n",
      "dense1.0.weight tensor(31707.0078)\n",
      "dense1.0.bias tensor(0.4164)\n",
      "dense2.0.weight tensor(50.4874)\n",
      "dense2.0.bias tensor(0.1867)\n",
      "conv1.0.weight tensor(4.4383)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.0202)\n",
      "conv1.2.bias tensor(0.0237)\n",
      "dense1.0.weight tensor(23133.3086)\n",
      "dense1.0.bias tensor(0.2613)\n",
      "dense2.0.weight tensor(34.9872)\n",
      "dense2.0.bias tensor(0.1330)\n",
      "conv1.0.weight tensor(2.4266)\n",
      "conv1.0.bias tensor(8.9233e-05)\n",
      "conv1.2.weight tensor(0.0399)\n",
      "conv1.2.bias tensor(0.0370)\n",
      "dense1.0.weight tensor(24560.0312)\n",
      "dense1.0.bias tensor(0.2923)\n",
      "dense2.0.weight tensor(43.0162)\n",
      "dense2.0.bias tensor(0.1606)\n",
      "conv1.0.weight tensor(6.0556)\n",
      "conv1.0.bias tensor(0.0003)\n",
      "conv1.2.weight tensor(0.0557)\n",
      "conv1.2.bias tensor(0.0755)\n",
      "dense1.0.weight tensor(32025.2402)\n",
      "dense1.0.bias tensor(0.4509)\n",
      "dense2.0.weight tensor(50.5309)\n",
      "dense2.0.bias tensor(0.2027)\n",
      "conv1.0.weight tensor(6.8214)\n",
      "conv1.0.bias tensor(7.5051e-05)\n",
      "conv1.2.weight tensor(0.0378)\n",
      "conv1.2.bias tensor(0.0530)\n",
      "dense1.0.weight tensor(31677.8438)\n",
      "dense1.0.bias tensor(0.3862)\n",
      "dense2.0.weight tensor(53.4981)\n",
      "dense2.0.bias tensor(0.1863)\n",
      "conv1.0.weight tensor(6.5946)\n",
      "conv1.0.bias tensor(0.0005)\n",
      "conv1.2.weight tensor(0.0519)\n",
      "conv1.2.bias tensor(0.0729)\n",
      "dense1.0.weight tensor(27883.9336)\n",
      "dense1.0.bias tensor(0.3668)\n",
      "dense2.0.weight tensor(43.6337)\n",
      "dense2.0.bias tensor(0.1689)\n",
      "conv1.0.weight tensor(5.6790)\n",
      "conv1.0.bias tensor(0.0003)\n",
      "conv1.2.weight tensor(0.0477)\n",
      "conv1.2.bias tensor(0.0403)\n",
      "dense1.0.weight tensor(29214.8672)\n",
      "dense1.0.bias tensor(0.3548)\n",
      "dense2.0.weight tensor(42.7097)\n",
      "dense2.0.bias tensor(0.1393)\n",
      "conv1.0.weight tensor(5.3885)\n",
      "conv1.0.bias tensor(0.0001)\n",
      "conv1.2.weight tensor(0.0113)\n",
      "conv1.2.bias tensor(0.0146)\n",
      "dense1.0.weight tensor(25166.1680)\n",
      "dense1.0.bias tensor(0.2634)\n",
      "dense2.0.weight tensor(34.4819)\n",
      "dense2.0.bias tensor(0.1074)\n",
      "conv1.0.weight tensor(3.5211)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.0752)\n",
      "conv1.2.bias tensor(0.0754)\n",
      "dense1.0.weight tensor(32862.5625)\n",
      "dense1.0.bias tensor(0.4357)\n",
      "dense2.0.weight tensor(49.9605)\n",
      "dense2.0.bias tensor(0.1596)\n",
      "conv1.0.weight tensor(4.7023)\n",
      "conv1.0.bias tensor(0.0003)\n",
      "conv1.2.weight tensor(0.0241)\n",
      "conv1.2.bias tensor(0.0375)\n",
      "dense1.0.weight tensor(27838.3535)\n",
      "dense1.0.bias tensor(0.3366)\n",
      "dense2.0.weight tensor(49.5675)\n",
      "dense2.0.bias tensor(0.1495)\n",
      "conv1.0.weight tensor(5.3481)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.0398)\n",
      "conv1.2.bias tensor(0.0564)\n",
      "dense1.0.weight tensor(23575.0938)\n",
      "dense1.0.bias tensor(0.2709)\n",
      "dense2.0.weight tensor(37.4369)\n",
      "dense2.0.bias tensor(0.1090)\n",
      "conv1.0.weight tensor(11.0970)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.0465)\n",
      "conv1.2.bias tensor(0.0648)\n",
      "dense1.0.weight tensor(36338.6523)\n",
      "dense1.0.bias tensor(0.4438)\n",
      "dense2.0.weight tensor(56.5584)\n",
      "dense2.0.bias tensor(0.1851)\n",
      "conv1.0.weight tensor(9.6868)\n",
      "conv1.0.bias tensor(0.0005)\n",
      "conv1.2.weight tensor(0.0333)\n",
      "conv1.2.bias tensor(0.0470)\n",
      "dense1.0.weight tensor(24395.8535)\n",
      "dense1.0.bias tensor(0.2225)\n",
      "dense2.0.weight tensor(32.9766)\n",
      "dense2.0.bias tensor(0.0798)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.0.weight tensor(11.1410)\n",
      "conv1.0.bias tensor(0.0006)\n",
      "conv1.2.weight tensor(0.0852)\n",
      "conv1.2.bias tensor(0.0677)\n",
      "dense1.0.weight tensor(31980.9434)\n",
      "dense1.0.bias tensor(0.3668)\n",
      "dense2.0.weight tensor(58.8249)\n",
      "dense2.0.bias tensor(0.1662)\n",
      "conv1.0.weight tensor(1.8644)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.0396)\n",
      "conv1.2.bias tensor(0.0351)\n",
      "dense1.0.weight tensor(28188.1465)\n",
      "dense1.0.bias tensor(0.3566)\n",
      "dense2.0.weight tensor(57.6760)\n",
      "dense2.0.bias tensor(0.1565)\n",
      "conv1.0.weight tensor(4.5336)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.0582)\n",
      "conv1.2.bias tensor(0.0550)\n",
      "dense1.0.weight tensor(29799.3281)\n",
      "dense1.0.bias tensor(0.3780)\n",
      "dense2.0.weight tensor(52.7415)\n",
      "dense2.0.bias tensor(0.1521)\n",
      "conv1.0.weight tensor(10.6559)\n",
      "conv1.0.bias tensor(0.0005)\n",
      "conv1.2.weight tensor(0.0567)\n",
      "conv1.2.bias tensor(0.0641)\n",
      "dense1.0.weight tensor(34252.4141)\n",
      "dense1.0.bias tensor(0.4802)\n",
      "dense2.0.weight tensor(69.2920)\n",
      "dense2.0.bias tensor(0.2113)\n",
      "conv1.0.weight tensor(9.2245)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.0373)\n",
      "conv1.2.bias tensor(0.0541)\n",
      "dense1.0.weight tensor(26387.5273)\n",
      "dense1.0.bias tensor(0.3308)\n",
      "dense2.0.weight tensor(48.0434)\n",
      "dense2.0.bias tensor(0.1521)\n",
      "conv1.0.weight tensor(8.1769)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.1043)\n",
      "conv1.2.bias tensor(0.0881)\n",
      "dense1.0.weight tensor(32620.6699)\n",
      "dense1.0.bias tensor(0.3713)\n",
      "dense2.0.weight tensor(61.8509)\n",
      "dense2.0.bias tensor(0.1728)\n",
      "conv1.0.weight tensor(7.4943)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.0328)\n",
      "conv1.2.bias tensor(0.0432)\n",
      "dense1.0.weight tensor(28078.9980)\n",
      "dense1.0.bias tensor(0.2685)\n",
      "dense2.0.weight tensor(52.7010)\n",
      "dense2.0.bias tensor(0.1068)\n",
      "conv1.0.weight tensor(6.8886)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.0434)\n",
      "conv1.2.bias tensor(0.0511)\n",
      "dense1.0.weight tensor(28866.1758)\n",
      "dense1.0.bias tensor(0.3187)\n",
      "dense2.0.weight tensor(58.1971)\n",
      "dense2.0.bias tensor(0.1467)\n",
      "conv1.0.weight tensor(6.7972)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.0470)\n",
      "conv1.2.bias tensor(0.0837)\n",
      "dense1.0.weight tensor(33946.3945)\n",
      "dense1.0.bias tensor(0.4170)\n",
      "dense2.0.weight tensor(64.4074)\n",
      "dense2.0.bias tensor(0.1998)\n",
      "conv1.0.weight tensor(6.7990)\n",
      "conv1.0.bias tensor(0.0001)\n",
      "conv1.2.weight tensor(0.0769)\n",
      "conv1.2.bias tensor(0.0822)\n",
      "dense1.0.weight tensor(26046.6230)\n",
      "dense1.0.bias tensor(0.3701)\n",
      "dense2.0.weight tensor(56.5039)\n",
      "dense2.0.bias tensor(0.1686)\n",
      "conv1.0.weight tensor(4.9349)\n",
      "conv1.0.bias tensor(0.0008)\n",
      "conv1.2.weight tensor(0.1073)\n",
      "conv1.2.bias tensor(0.0988)\n",
      "dense1.0.weight tensor(31714.5352)\n",
      "dense1.0.bias tensor(0.4736)\n",
      "dense2.0.weight tensor(76.8732)\n",
      "dense2.0.bias tensor(0.2480)\n",
      "conv1.0.weight tensor(4.1937)\n",
      "conv1.0.bias tensor(0.0003)\n",
      "conv1.2.weight tensor(0.0605)\n",
      "conv1.2.bias tensor(0.0438)\n",
      "dense1.0.weight tensor(23450.9512)\n",
      "dense1.0.bias tensor(0.2857)\n",
      "dense2.0.weight tensor(46.8380)\n",
      "dense2.0.bias tensor(0.1332)\n",
      "conv1.0.weight tensor(9.7921)\n",
      "conv1.0.bias tensor(0.0001)\n",
      "conv1.2.weight tensor(0.0642)\n",
      "conv1.2.bias tensor(0.0943)\n",
      "dense1.0.weight tensor(26084.8652)\n",
      "dense1.0.bias tensor(0.3296)\n",
      "dense2.0.weight tensor(57.9477)\n",
      "dense2.0.bias tensor(0.1647)\n",
      "conv1.0.weight tensor(15.8857)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.0898)\n",
      "conv1.2.bias tensor(0.0877)\n",
      "dense1.0.weight tensor(46969.4922)\n",
      "dense1.0.bias tensor(0.5922)\n",
      "dense2.0.weight tensor(96.9762)\n",
      "dense2.0.bias tensor(0.2710)\n",
      "conv1.0.weight tensor(4.5699)\n",
      "conv1.0.bias tensor(0.0003)\n",
      "conv1.2.weight tensor(0.0529)\n",
      "conv1.2.bias tensor(0.0493)\n",
      "dense1.0.weight tensor(18940.6992)\n",
      "dense1.0.bias tensor(0.2364)\n",
      "dense2.0.weight tensor(45.7775)\n",
      "dense2.0.bias tensor(0.1339)\n",
      "conv1.0.weight tensor(5.2992)\n",
      "conv1.0.bias tensor(0.0003)\n",
      "conv1.2.weight tensor(0.0791)\n",
      "conv1.2.bias tensor(0.1033)\n",
      "dense1.0.weight tensor(31224.8691)\n",
      "dense1.0.bias tensor(0.4267)\n",
      "dense2.0.weight tensor(53.1482)\n",
      "dense2.0.bias tensor(0.1581)\n",
      "conv1.0.weight tensor(8.2620)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.0400)\n",
      "conv1.2.bias tensor(0.0626)\n",
      "dense1.0.weight tensor(23853.7051)\n",
      "dense1.0.bias tensor(0.2289)\n",
      "dense2.0.weight tensor(41.0452)\n",
      "dense2.0.bias tensor(0.0992)\n",
      "conv1.0.weight tensor(6.3555)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.0801)\n",
      "conv1.2.bias tensor(0.1229)\n",
      "dense1.0.weight tensor(32933.2812)\n",
      "dense1.0.bias tensor(0.4432)\n",
      "dense2.0.weight tensor(64.4795)\n",
      "dense2.0.bias tensor(0.1900)\n",
      "conv1.0.weight tensor(10.3878)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.0703)\n",
      "conv1.2.bias tensor(0.0980)\n",
      "dense1.0.weight tensor(30166.0586)\n",
      "dense1.0.bias tensor(0.4176)\n",
      "dense2.0.weight tensor(63.1231)\n",
      "dense2.0.bias tensor(0.1836)\n",
      "conv1.0.weight tensor(10.7606)\n",
      "conv1.0.bias tensor(0.0005)\n",
      "conv1.2.weight tensor(0.0630)\n",
      "conv1.2.bias tensor(0.0695)\n",
      "dense1.0.weight tensor(27400.6680)\n",
      "dense1.0.bias tensor(0.3280)\n",
      "dense2.0.weight tensor(54.7468)\n",
      "dense2.0.bias tensor(0.1581)\n",
      "conv1.0.weight tensor(11.9118)\n",
      "conv1.0.bias tensor(0.0003)\n",
      "conv1.2.weight tensor(0.0343)\n",
      "conv1.2.bias tensor(0.0344)\n",
      "dense1.0.weight tensor(30388.6445)\n",
      "dense1.0.bias tensor(0.3584)\n",
      "dense2.0.weight tensor(61.1305)\n",
      "dense2.0.bias tensor(0.1694)\n",
      "conv1.0.weight tensor(6.2360)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.0444)\n",
      "conv1.2.bias tensor(0.0579)\n",
      "dense1.0.weight tensor(26759.2754)\n",
      "dense1.0.bias tensor(0.3472)\n",
      "dense2.0.weight tensor(56.9653)\n",
      "dense2.0.bias tensor(0.1530)\n",
      "conv1.0.weight tensor(4.9117)\n",
      "conv1.0.bias tensor(0.0006)\n",
      "conv1.2.weight tensor(0.0858)\n",
      "conv1.2.bias tensor(0.0922)\n",
      "dense1.0.weight tensor(31454.9961)\n",
      "dense1.0.bias tensor(0.3525)\n",
      "dense2.0.weight tensor(63.2827)\n",
      "dense2.0.bias tensor(0.1659)\n",
      "conv1.0.weight tensor(10.9079)\n",
      "conv1.0.bias tensor(0.0003)\n",
      "conv1.2.weight tensor(0.0362)\n",
      "conv1.2.bias tensor(0.0510)\n",
      "dense1.0.weight tensor(33732.7109)\n",
      "dense1.0.bias tensor(0.3963)\n",
      "dense2.0.weight tensor(63.8033)\n",
      "dense2.0.bias tensor(0.1855)\n",
      "conv1.0.weight tensor(5.3462)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.0302)\n",
      "conv1.2.bias tensor(0.0734)\n",
      "dense1.0.weight tensor(23599.0938)\n",
      "dense1.0.bias tensor(0.3017)\n",
      "dense2.0.weight tensor(43.1867)\n",
      "dense2.0.bias tensor(0.1187)\n",
      "conv1.0.weight tensor(4.9758)\n",
      "conv1.0.bias tensor(0.0001)\n",
      "conv1.2.weight tensor(0.0479)\n",
      "conv1.2.bias tensor(0.0771)\n",
      "dense1.0.weight tensor(30779.9062)\n",
      "dense1.0.bias tensor(0.3642)\n",
      "dense2.0.weight tensor(59.3972)\n",
      "dense2.0.bias tensor(0.1457)\n",
      "conv1.0.weight tensor(11.4355)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.0951)\n",
      "conv1.2.bias tensor(0.1169)\n",
      "dense1.0.weight tensor(25174.1914)\n",
      "dense1.0.bias tensor(0.3060)\n",
      "dense2.0.weight tensor(48.2142)\n",
      "dense2.0.bias tensor(0.1256)\n",
      "conv1.0.weight tensor(8.9495)\n",
      "conv1.0.bias tensor(0.0003)\n",
      "conv1.2.weight tensor(0.0873)\n",
      "conv1.2.bias tensor(0.0978)\n",
      "dense1.0.weight tensor(25349.5703)\n",
      "dense1.0.bias tensor(0.3370)\n",
      "dense2.0.weight tensor(56.6583)\n",
      "dense2.0.bias tensor(0.1427)\n",
      "conv1.0.weight tensor(11.3988)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.0585)\n",
      "conv1.2.bias tensor(0.0589)\n",
      "dense1.0.weight tensor(23405.5312)\n",
      "dense1.0.bias tensor(0.3009)\n",
      "dense2.0.weight tensor(51.8474)\n",
      "dense2.0.bias tensor(0.1250)\n",
      "conv1.0.weight tensor(8.1062)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.0483)\n",
      "conv1.2.bias tensor(0.0607)\n",
      "dense1.0.weight tensor(28169.6152)\n",
      "dense1.0.bias tensor(0.3455)\n",
      "dense2.0.weight tensor(54.6931)\n",
      "dense2.0.bias tensor(0.1635)\n",
      "conv1.0.weight tensor(8.8420)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.0741)\n",
      "conv1.2.bias tensor(0.0915)\n",
      "dense1.0.weight tensor(31315.9355)\n",
      "dense1.0.bias tensor(0.3667)\n",
      "dense2.0.weight tensor(68.3830)\n",
      "dense2.0.bias tensor(0.1738)\n",
      "conv1.0.weight tensor(9.1048)\n",
      "conv1.0.bias tensor(0.0001)\n",
      "conv1.2.weight tensor(0.0725)\n",
      "conv1.2.bias tensor(0.0461)\n",
      "dense1.0.weight tensor(25267.9785)\n",
      "dense1.0.bias tensor(0.2758)\n",
      "dense2.0.weight tensor(50.0251)\n",
      "dense2.0.bias tensor(0.1164)\n",
      "conv1.0.weight tensor(14.5756)\n",
      "conv1.0.bias tensor(0.0007)\n",
      "conv1.2.weight tensor(0.0436)\n",
      "conv1.2.bias tensor(0.0712)\n",
      "dense1.0.weight tensor(26587.8320)\n",
      "dense1.0.bias tensor(0.3068)\n",
      "dense2.0.weight tensor(53.7931)\n",
      "dense2.0.bias tensor(0.1348)\n",
      "conv1.0.weight tensor(12.6538)\n",
      "conv1.0.bias tensor(0.0003)\n",
      "conv1.2.weight tensor(0.0897)\n",
      "conv1.2.bias tensor(0.1394)\n",
      "dense1.0.weight tensor(26546.3320)\n",
      "dense1.0.bias tensor(0.3015)\n",
      "dense2.0.weight tensor(54.7371)\n",
      "dense2.0.bias tensor(0.1257)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.0.weight tensor(10.0650)\n",
      "conv1.0.bias tensor(0.0003)\n",
      "conv1.2.weight tensor(0.0944)\n",
      "conv1.2.bias tensor(0.1456)\n",
      "dense1.0.weight tensor(30526.5957)\n",
      "dense1.0.bias tensor(0.3977)\n",
      "dense2.0.weight tensor(67.5346)\n",
      "dense2.0.bias tensor(0.1756)\n",
      "conv1.0.weight tensor(4.6757)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.1139)\n",
      "conv1.2.bias tensor(0.1248)\n",
      "dense1.0.weight tensor(24137.5391)\n",
      "dense1.0.bias tensor(0.3186)\n",
      "dense2.0.weight tensor(55.8072)\n",
      "dense2.0.bias tensor(0.1428)\n",
      "conv1.0.weight tensor(16.9936)\n",
      "conv1.0.bias tensor(0.0003)\n",
      "conv1.2.weight tensor(0.1311)\n",
      "conv1.2.bias tensor(0.1203)\n",
      "dense1.0.weight tensor(28957.9375)\n",
      "dense1.0.bias tensor(0.3198)\n",
      "dense2.0.weight tensor(51.0608)\n",
      "dense2.0.bias tensor(0.1166)\n",
      "conv1.0.weight tensor(3.6424)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.0409)\n",
      "conv1.2.bias tensor(0.0461)\n",
      "dense1.0.weight tensor(32029.7051)\n",
      "dense1.0.bias tensor(0.3365)\n",
      "dense2.0.weight tensor(61.7386)\n",
      "dense2.0.bias tensor(0.1364)\n",
      "conv1.0.weight tensor(25.1395)\n",
      "conv1.0.bias tensor(0.0008)\n",
      "conv1.2.weight tensor(0.1134)\n",
      "conv1.2.bias tensor(0.1746)\n",
      "dense1.0.weight tensor(32591.2695)\n",
      "dense1.0.bias tensor(0.4166)\n",
      "dense2.0.weight tensor(66.3386)\n",
      "dense2.0.bias tensor(0.1451)\n",
      "conv1.0.weight tensor(5.2296)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.0698)\n",
      "conv1.2.bias tensor(0.0674)\n",
      "dense1.0.weight tensor(24973.3672)\n",
      "dense1.0.bias tensor(0.2906)\n",
      "dense2.0.weight tensor(56.6875)\n",
      "dense2.0.bias tensor(0.1401)\n",
      "conv1.0.weight tensor(5.5135)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.0819)\n",
      "conv1.2.bias tensor(0.0972)\n",
      "dense1.0.weight tensor(26604.4844)\n",
      "dense1.0.bias tensor(0.3401)\n",
      "dense2.0.weight tensor(52.5799)\n",
      "dense2.0.bias tensor(0.1254)\n",
      "conv1.0.weight tensor(12.8290)\n",
      "conv1.0.bias tensor(0.0005)\n",
      "conv1.2.weight tensor(0.0908)\n",
      "conv1.2.bias tensor(0.1192)\n",
      "dense1.0.weight tensor(29506.4414)\n",
      "dense1.0.bias tensor(0.3661)\n",
      "dense2.0.weight tensor(66.4159)\n",
      "dense2.0.bias tensor(0.1469)\n",
      "conv1.0.weight tensor(2.8456)\n",
      "conv1.0.bias tensor(0.0003)\n",
      "conv1.2.weight tensor(0.0777)\n",
      "conv1.2.bias tensor(0.0861)\n",
      "dense1.0.weight tensor(27368.1797)\n",
      "dense1.0.bias tensor(0.3541)\n",
      "dense2.0.weight tensor(62.7951)\n",
      "dense2.0.bias tensor(0.1672)\n",
      "conv1.0.weight tensor(5.9466)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.0618)\n",
      "conv1.2.bias tensor(0.0609)\n",
      "dense1.0.weight tensor(24819.2266)\n",
      "dense1.0.bias tensor(0.2886)\n",
      "dense2.0.weight tensor(57.5655)\n",
      "dense2.0.bias tensor(0.1350)\n",
      "conv1.0.weight tensor(11.8381)\n",
      "conv1.0.bias tensor(0.0003)\n",
      "conv1.2.weight tensor(0.0805)\n",
      "conv1.2.bias tensor(0.0954)\n",
      "dense1.0.weight tensor(21774.6875)\n",
      "dense1.0.bias tensor(0.2685)\n",
      "dense2.0.weight tensor(47.7525)\n",
      "dense2.0.bias tensor(0.1189)\n",
      "conv1.0.weight tensor(4.9915)\n",
      "conv1.0.bias tensor(0.0001)\n",
      "conv1.2.weight tensor(0.0866)\n",
      "conv1.2.bias tensor(0.1110)\n",
      "dense1.0.weight tensor(29623.5859)\n",
      "dense1.0.bias tensor(0.3637)\n",
      "dense2.0.weight tensor(74.5563)\n",
      "dense2.0.bias tensor(0.1913)\n",
      "conv1.0.weight tensor(10.4636)\n",
      "conv1.0.bias tensor(0.0012)\n",
      "conv1.2.weight tensor(0.0816)\n",
      "conv1.2.bias tensor(0.1211)\n",
      "dense1.0.weight tensor(26644.6953)\n",
      "dense1.0.bias tensor(0.2913)\n",
      "dense2.0.weight tensor(57.3914)\n",
      "dense2.0.bias tensor(0.1201)\n",
      "conv1.0.weight tensor(9.0231)\n",
      "conv1.0.bias tensor(0.0005)\n",
      "conv1.2.weight tensor(0.1666)\n",
      "conv1.2.bias tensor(0.1881)\n",
      "dense1.0.weight tensor(29525.5625)\n",
      "dense1.0.bias tensor(0.3559)\n",
      "dense2.0.weight tensor(65.2356)\n",
      "dense2.0.bias tensor(0.1596)\n",
      "conv1.0.weight tensor(5.2979)\n",
      "conv1.0.bias tensor(0.0003)\n",
      "conv1.2.weight tensor(0.0920)\n",
      "conv1.2.bias tensor(0.0693)\n",
      "dense1.0.weight tensor(21412.8887)\n",
      "dense1.0.bias tensor(0.2439)\n",
      "dense2.0.weight tensor(43.8093)\n",
      "dense2.0.bias tensor(0.0975)\n",
      "conv1.0.weight tensor(7.7989)\n",
      "conv1.0.bias tensor(0.0003)\n",
      "conv1.2.weight tensor(0.0817)\n",
      "conv1.2.bias tensor(0.0910)\n",
      "dense1.0.weight tensor(31008.6406)\n",
      "dense1.0.bias tensor(0.3588)\n",
      "dense2.0.weight tensor(73.7668)\n",
      "dense2.0.bias tensor(0.1746)\n",
      "conv1.0.weight tensor(16.5729)\n",
      "conv1.0.bias tensor(0.0003)\n",
      "conv1.2.weight tensor(0.0652)\n",
      "conv1.2.bias tensor(0.0527)\n",
      "dense1.0.weight tensor(26958.9531)\n",
      "dense1.0.bias tensor(0.3238)\n",
      "dense2.0.weight tensor(64.0312)\n",
      "dense2.0.bias tensor(0.1555)\n",
      "conv1.0.weight tensor(7.0126)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.0384)\n",
      "conv1.2.bias tensor(0.0338)\n",
      "dense1.0.weight tensor(18163.2461)\n",
      "dense1.0.bias tensor(0.2215)\n",
      "dense2.0.weight tensor(47.0949)\n",
      "dense2.0.bias tensor(0.1001)\n",
      "conv1.0.weight tensor(13.1259)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.1215)\n",
      "conv1.2.bias tensor(0.1418)\n",
      "dense1.0.weight tensor(37963.8789)\n",
      "dense1.0.bias tensor(0.4747)\n",
      "dense2.0.weight tensor(83.2358)\n",
      "dense2.0.bias tensor(0.1956)\n",
      "conv1.0.weight tensor(12.7034)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.1087)\n",
      "conv1.2.bias tensor(0.1589)\n",
      "dense1.0.weight tensor(31689.1328)\n",
      "dense1.0.bias tensor(0.3624)\n",
      "dense2.0.weight tensor(63.3780)\n",
      "dense2.0.bias tensor(0.1226)\n",
      "conv1.0.weight tensor(5.6065)\n",
      "conv1.0.bias tensor(9.0005e-05)\n",
      "conv1.2.weight tensor(0.0580)\n",
      "conv1.2.bias tensor(0.0754)\n",
      "dense1.0.weight tensor(19149.7871)\n",
      "dense1.0.bias tensor(0.2308)\n",
      "dense2.0.weight tensor(38.1241)\n",
      "dense2.0.bias tensor(0.0949)\n",
      "conv1.0.weight tensor(16.3693)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.0908)\n",
      "conv1.2.bias tensor(0.1222)\n",
      "dense1.0.weight tensor(28398.6484)\n",
      "dense1.0.bias tensor(0.3729)\n",
      "dense2.0.weight tensor(66.6003)\n",
      "dense2.0.bias tensor(0.1799)\n",
      "conv1.0.weight tensor(10.2136)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.0641)\n",
      "conv1.2.bias tensor(0.1052)\n",
      "dense1.0.weight tensor(26264.7148)\n",
      "dense1.0.bias tensor(0.3866)\n",
      "dense2.0.weight tensor(63.8826)\n",
      "dense2.0.bias tensor(0.1744)\n",
      "conv1.0.weight tensor(10.1226)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.1268)\n",
      "conv1.2.bias tensor(0.1184)\n",
      "dense1.0.weight tensor(29308.4785)\n",
      "dense1.0.bias tensor(0.3714)\n",
      "dense2.0.weight tensor(67.5025)\n",
      "dense2.0.bias tensor(0.1653)\n",
      "conv1.0.weight tensor(8.1711)\n",
      "conv1.0.bias tensor(0.0003)\n",
      "conv1.2.weight tensor(0.0166)\n",
      "conv1.2.bias tensor(0.0252)\n",
      "dense1.0.weight tensor(22463.8184)\n",
      "dense1.0.bias tensor(0.2403)\n",
      "dense2.0.weight tensor(50.5172)\n",
      "dense2.0.bias tensor(0.1237)\n",
      "conv1.0.weight tensor(13.7389)\n",
      "conv1.0.bias tensor(0.0001)\n",
      "conv1.2.weight tensor(0.1055)\n",
      "conv1.2.bias tensor(0.1474)\n",
      "dense1.0.weight tensor(24563.7344)\n",
      "dense1.0.bias tensor(0.3872)\n",
      "dense2.0.weight tensor(69.5297)\n",
      "dense2.0.bias tensor(0.1805)\n",
      "conv1.0.weight tensor(23.6369)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.0546)\n",
      "conv1.2.bias tensor(0.0871)\n",
      "dense1.0.weight tensor(28304.0664)\n",
      "dense1.0.bias tensor(0.3518)\n",
      "dense2.0.weight tensor(53.7920)\n",
      "dense2.0.bias tensor(0.1448)\n",
      "conv1.0.weight tensor(8.6271)\n",
      "conv1.0.bias tensor(0.0001)\n",
      "conv1.2.weight tensor(0.0470)\n",
      "conv1.2.bias tensor(0.0686)\n",
      "dense1.0.weight tensor(24000.3359)\n",
      "dense1.0.bias tensor(0.3562)\n",
      "dense2.0.weight tensor(62.5558)\n",
      "dense2.0.bias tensor(0.1659)\n",
      "conv1.0.weight tensor(8.7530)\n",
      "conv1.0.bias tensor(0.0006)\n",
      "conv1.2.weight tensor(0.1186)\n",
      "conv1.2.bias tensor(0.1284)\n",
      "dense1.0.weight tensor(34889.)\n",
      "dense1.0.bias tensor(0.3939)\n",
      "dense2.0.weight tensor(73.6910)\n",
      "dense2.0.bias tensor(0.1459)\n",
      "conv1.0.weight tensor(7.6170)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.1452)\n",
      "conv1.2.bias tensor(0.1650)\n",
      "dense1.0.weight tensor(28085.7012)\n",
      "dense1.0.bias tensor(0.3602)\n",
      "dense2.0.weight tensor(74.5351)\n",
      "dense2.0.bias tensor(0.1782)\n",
      "conv1.0.weight tensor(16.8082)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.0895)\n",
      "conv1.2.bias tensor(0.0845)\n",
      "dense1.0.weight tensor(24884.1230)\n",
      "dense1.0.bias tensor(0.2508)\n",
      "dense2.0.weight tensor(52.8845)\n",
      "dense2.0.bias tensor(0.1039)\n",
      "conv1.0.weight tensor(8.7873)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.1005)\n",
      "conv1.2.bias tensor(0.1142)\n",
      "dense1.0.weight tensor(31206.9902)\n",
      "dense1.0.bias tensor(0.4022)\n",
      "dense2.0.weight tensor(72.6028)\n",
      "dense2.0.bias tensor(0.1625)\n",
      "conv1.0.weight tensor(6.2716)\n",
      "conv1.0.bias tensor(0.0005)\n",
      "conv1.2.weight tensor(0.0715)\n",
      "conv1.2.bias tensor(0.0721)\n",
      "dense1.0.weight tensor(26326.5625)\n",
      "dense1.0.bias tensor(0.3243)\n",
      "dense2.0.weight tensor(62.7685)\n",
      "dense2.0.bias tensor(0.1316)\n",
      "conv1.0.weight tensor(19.1857)\n",
      "conv1.0.bias tensor(0.0005)\n",
      "conv1.2.weight tensor(0.1471)\n",
      "conv1.2.bias tensor(0.1513)\n",
      "dense1.0.weight tensor(35923.0977)\n",
      "dense1.0.bias tensor(0.4504)\n",
      "dense2.0.weight tensor(94.7965)\n",
      "dense2.0.bias tensor(0.2190)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.0.weight tensor(34.1327)\n",
      "conv1.0.bias tensor(0.0005)\n",
      "conv1.2.weight tensor(0.1025)\n",
      "conv1.2.bias tensor(0.1273)\n",
      "dense1.0.weight tensor(32136.4980)\n",
      "dense1.0.bias tensor(0.4730)\n",
      "dense2.0.weight tensor(79.7849)\n",
      "dense2.0.bias tensor(0.2057)\n",
      "conv1.0.weight tensor(9.7531)\n",
      "conv1.0.bias tensor(0.0009)\n",
      "conv1.2.weight tensor(0.0828)\n",
      "conv1.2.bias tensor(0.0823)\n",
      "dense1.0.weight tensor(29355.7148)\n",
      "dense1.0.bias tensor(0.2992)\n",
      "dense2.0.weight tensor(63.5932)\n",
      "dense2.0.bias tensor(0.1356)\n",
      "conv1.0.weight tensor(15.9986)\n",
      "conv1.0.bias tensor(0.0003)\n",
      "conv1.2.weight tensor(0.1591)\n",
      "conv1.2.bias tensor(0.1793)\n",
      "dense1.0.weight tensor(35815.2500)\n",
      "dense1.0.bias tensor(0.4313)\n",
      "dense2.0.weight tensor(82.9428)\n",
      "dense2.0.bias tensor(0.1908)\n",
      "conv1.0.weight tensor(30.1388)\n",
      "conv1.0.bias tensor(7.7405e-05)\n",
      "conv1.2.weight tensor(0.1359)\n",
      "conv1.2.bias tensor(0.1733)\n",
      "dense1.0.weight tensor(36690.2070)\n",
      "dense1.0.bias tensor(0.4600)\n",
      "dense2.0.weight tensor(88.7476)\n",
      "dense2.0.bias tensor(0.1775)\n",
      "conv1.0.weight tensor(11.5945)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.1119)\n",
      "conv1.2.bias tensor(0.1378)\n",
      "dense1.0.weight tensor(29141.3125)\n",
      "dense1.0.bias tensor(0.3466)\n",
      "dense2.0.weight tensor(65.4947)\n",
      "dense2.0.bias tensor(0.1672)\n",
      "conv1.0.weight tensor(25.2945)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.1303)\n",
      "conv1.2.bias tensor(0.1354)\n",
      "dense1.0.weight tensor(29820.0234)\n",
      "dense1.0.bias tensor(0.3785)\n",
      "dense2.0.weight tensor(72.1243)\n",
      "dense2.0.bias tensor(0.1745)\n",
      "conv1.0.weight tensor(17.6050)\n",
      "conv1.0.bias tensor(0.0010)\n",
      "conv1.2.weight tensor(0.0979)\n",
      "conv1.2.bias tensor(0.0780)\n",
      "dense1.0.weight tensor(31151.2500)\n",
      "dense1.0.bias tensor(0.3521)\n",
      "dense2.0.weight tensor(72.7822)\n",
      "dense2.0.bias tensor(0.1629)\n",
      "conv1.0.weight tensor(9.2512)\n",
      "conv1.0.bias tensor(0.0014)\n",
      "conv1.2.weight tensor(0.1137)\n",
      "conv1.2.bias tensor(0.1543)\n",
      "dense1.0.weight tensor(30897.2090)\n",
      "dense1.0.bias tensor(0.4090)\n",
      "dense2.0.weight tensor(88.4829)\n",
      "dense2.0.bias tensor(0.1931)\n",
      "conv1.0.weight tensor(28.7453)\n",
      "conv1.0.bias tensor(0.0001)\n",
      "conv1.2.weight tensor(0.1651)\n",
      "conv1.2.bias tensor(0.1256)\n",
      "dense1.0.weight tensor(30115.1055)\n",
      "dense1.0.bias tensor(0.3603)\n",
      "dense2.0.weight tensor(78.6082)\n",
      "dense2.0.bias tensor(0.1684)\n",
      "conv1.0.weight tensor(71.2851)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.6364)\n",
      "conv1.2.bias tensor(0.5387)\n",
      "dense1.0.weight tensor(75617.8828)\n",
      "dense1.0.bias tensor(1.1499)\n",
      "dense2.0.weight tensor(181.8205)\n",
      "dense2.0.bias tensor(0.4048)\n",
      "conv1.0.weight tensor(11.0042)\n",
      "conv1.0.bias tensor(0.0005)\n",
      "conv1.2.weight tensor(0.1118)\n",
      "conv1.2.bias tensor(0.1092)\n",
      "dense1.0.weight tensor(24664.9375)\n",
      "dense1.0.bias tensor(0.3069)\n",
      "dense2.0.weight tensor(58.1102)\n",
      "dense2.0.bias tensor(0.1063)\n",
      "conv1.0.weight tensor(17.6452)\n",
      "conv1.0.bias tensor(0.0010)\n",
      "conv1.2.weight tensor(0.1084)\n",
      "conv1.2.bias tensor(0.1100)\n",
      "dense1.0.weight tensor(32806.9570)\n",
      "dense1.0.bias tensor(0.4360)\n",
      "dense2.0.weight tensor(93.1029)\n",
      "dense2.0.bias tensor(0.2075)\n",
      "conv1.0.weight tensor(12.6780)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.0594)\n",
      "conv1.2.bias tensor(0.0809)\n",
      "dense1.0.weight tensor(29792.4961)\n",
      "dense1.0.bias tensor(0.4612)\n",
      "dense2.0.weight tensor(76.2734)\n",
      "dense2.0.bias tensor(0.1889)\n",
      "conv1.0.weight tensor(20.4793)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.1686)\n",
      "conv1.2.bias tensor(0.2090)\n",
      "dense1.0.weight tensor(34727.9609)\n",
      "dense1.0.bias tensor(0.4948)\n",
      "dense2.0.weight tensor(113.2812)\n",
      "dense2.0.bias tensor(0.2573)\n",
      "conv1.0.weight tensor(15.7693)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.1441)\n",
      "conv1.2.bias tensor(0.1241)\n",
      "dense1.0.weight tensor(38923.8633)\n",
      "dense1.0.bias tensor(0.5083)\n",
      "dense2.0.weight tensor(101.6299)\n",
      "dense2.0.bias tensor(0.2137)\n",
      "conv1.0.weight tensor(9.2636)\n",
      "conv1.0.bias tensor(0.0007)\n",
      "conv1.2.weight tensor(0.0827)\n",
      "conv1.2.bias tensor(0.1002)\n",
      "dense1.0.weight tensor(24847.6855)\n",
      "dense1.0.bias tensor(0.2984)\n",
      "dense2.0.weight tensor(62.5781)\n",
      "dense2.0.bias tensor(0.1367)\n",
      "conv1.0.weight tensor(14.8200)\n",
      "conv1.0.bias tensor(0.0005)\n",
      "conv1.2.weight tensor(0.1102)\n",
      "conv1.2.bias tensor(0.1488)\n",
      "dense1.0.weight tensor(25081.7578)\n",
      "dense1.0.bias tensor(0.3159)\n",
      "dense2.0.weight tensor(67.4645)\n",
      "dense2.0.bias tensor(0.1456)\n",
      "conv1.0.weight tensor(21.6762)\n",
      "conv1.0.bias tensor(0.0007)\n",
      "conv1.2.weight tensor(0.1892)\n",
      "conv1.2.bias tensor(0.1796)\n",
      "dense1.0.weight tensor(34386.9141)\n",
      "dense1.0.bias tensor(0.4488)\n",
      "dense2.0.weight tensor(89.8481)\n",
      "dense2.0.bias tensor(0.2086)\n",
      "conv1.0.weight tensor(26.3517)\n",
      "conv1.0.bias tensor(0.0007)\n",
      "conv1.2.weight tensor(0.1862)\n",
      "conv1.2.bias tensor(0.1481)\n",
      "dense1.0.weight tensor(27427.5703)\n",
      "dense1.0.bias tensor(0.3454)\n",
      "dense2.0.weight tensor(75.0016)\n",
      "dense2.0.bias tensor(0.1774)\n",
      "conv1.0.weight tensor(9.2094)\n",
      "conv1.0.bias tensor(0.0005)\n",
      "conv1.2.weight tensor(0.1819)\n",
      "conv1.2.bias tensor(0.2759)\n",
      "dense1.0.weight tensor(32228.0547)\n",
      "dense1.0.bias tensor(0.4567)\n",
      "dense2.0.weight tensor(80.4436)\n",
      "dense2.0.bias tensor(0.1912)\n",
      "conv1.0.weight tensor(10.9856)\n",
      "conv1.0.bias tensor(0.0011)\n",
      "conv1.2.weight tensor(0.1960)\n",
      "conv1.2.bias tensor(0.2380)\n",
      "dense1.0.weight tensor(25627.0625)\n",
      "dense1.0.bias tensor(0.3596)\n",
      "dense2.0.weight tensor(67.4975)\n",
      "dense2.0.bias tensor(0.1560)\n",
      "conv1.0.weight tensor(13.3055)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.0881)\n",
      "conv1.2.bias tensor(0.0992)\n",
      "dense1.0.weight tensor(24943.9160)\n",
      "dense1.0.bias tensor(0.3211)\n",
      "dense2.0.weight tensor(63.8756)\n",
      "dense2.0.bias tensor(0.1454)\n",
      "conv1.0.weight tensor(14.8750)\n",
      "conv1.0.bias tensor(0.0009)\n",
      "conv1.2.weight tensor(0.1352)\n",
      "conv1.2.bias tensor(0.0912)\n",
      "dense1.0.weight tensor(32313.2422)\n",
      "dense1.0.bias tensor(0.3900)\n",
      "dense2.0.weight tensor(88.2100)\n",
      "dense2.0.bias tensor(0.1969)\n",
      "conv1.0.weight tensor(18.6511)\n",
      "conv1.0.bias tensor(0.0009)\n",
      "conv1.2.weight tensor(0.1689)\n",
      "conv1.2.bias tensor(0.2128)\n",
      "dense1.0.weight tensor(38298.4766)\n",
      "dense1.0.bias tensor(0.5362)\n",
      "dense2.0.weight tensor(113.1744)\n",
      "dense2.0.bias tensor(0.2481)\n",
      "conv1.0.weight tensor(15.7442)\n",
      "conv1.0.bias tensor(0.0006)\n",
      "conv1.2.weight tensor(0.0995)\n",
      "conv1.2.bias tensor(0.1282)\n",
      "dense1.0.weight tensor(32000.6895)\n",
      "dense1.0.bias tensor(0.3949)\n",
      "dense2.0.weight tensor(85.0441)\n",
      "dense2.0.bias tensor(0.1694)\n",
      "conv1.0.weight tensor(14.3058)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.1244)\n",
      "conv1.2.bias tensor(0.1453)\n",
      "dense1.0.weight tensor(30957.3984)\n",
      "dense1.0.bias tensor(0.4204)\n",
      "dense2.0.weight tensor(94.0364)\n",
      "dense2.0.bias tensor(0.2060)\n",
      "conv1.0.weight tensor(20.5523)\n",
      "conv1.0.bias tensor(0.0008)\n",
      "conv1.2.weight tensor(0.1096)\n",
      "conv1.2.bias tensor(0.1154)\n",
      "dense1.0.weight tensor(30320.8242)\n",
      "dense1.0.bias tensor(0.3180)\n",
      "dense2.0.weight tensor(81.3820)\n",
      "dense2.0.bias tensor(0.1563)\n",
      "conv1.0.weight tensor(8.5967)\n",
      "conv1.0.bias tensor(0.0003)\n",
      "conv1.2.weight tensor(0.0903)\n",
      "conv1.2.bias tensor(0.1153)\n",
      "dense1.0.weight tensor(31007.6914)\n",
      "dense1.0.bias tensor(0.3782)\n",
      "dense2.0.weight tensor(79.0759)\n",
      "dense2.0.bias tensor(0.1758)\n",
      "conv1.0.weight tensor(7.0944)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.0852)\n",
      "conv1.2.bias tensor(0.0966)\n",
      "dense1.0.weight tensor(24330.2070)\n",
      "dense1.0.bias tensor(0.2739)\n",
      "dense2.0.weight tensor(66.7122)\n",
      "dense2.0.bias tensor(0.1392)\n",
      "conv1.0.weight tensor(27.2782)\n",
      "conv1.0.bias tensor(0.0007)\n",
      "conv1.2.weight tensor(0.2169)\n",
      "conv1.2.bias tensor(0.3041)\n",
      "dense1.0.weight tensor(36123.8359)\n",
      "dense1.0.bias tensor(0.5300)\n",
      "dense2.0.weight tensor(118.0925)\n",
      "dense2.0.bias tensor(0.2686)\n",
      "conv1.0.weight tensor(11.0185)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.0904)\n",
      "conv1.2.bias tensor(0.0850)\n",
      "dense1.0.weight tensor(27702.4727)\n",
      "dense1.0.bias tensor(0.2898)\n",
      "dense2.0.weight tensor(76.6898)\n",
      "dense2.0.bias tensor(0.1384)\n",
      "conv1.0.weight tensor(25.1881)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.1781)\n",
      "conv1.2.bias tensor(0.2002)\n",
      "dense1.0.weight tensor(33629.4688)\n",
      "dense1.0.bias tensor(0.4074)\n",
      "dense2.0.weight tensor(98.2295)\n",
      "dense2.0.bias tensor(0.2077)\n",
      "conv1.0.weight tensor(20.3228)\n",
      "conv1.0.bias tensor(0.0003)\n",
      "conv1.2.weight tensor(0.2999)\n",
      "conv1.2.bias tensor(0.3772)\n",
      "dense1.0.weight tensor(42156.8281)\n",
      "dense1.0.bias tensor(0.5419)\n",
      "dense2.0.weight tensor(123.8016)\n",
      "dense2.0.bias tensor(0.2714)\n",
      "conv1.0.weight tensor(20.7825)\n",
      "conv1.0.bias tensor(0.0007)\n",
      "conv1.2.weight tensor(0.1557)\n",
      "conv1.2.bias tensor(0.2422)\n",
      "dense1.0.weight tensor(39505.1211)\n",
      "dense1.0.bias tensor(0.5939)\n",
      "dense2.0.weight tensor(143.4536)\n",
      "dense2.0.bias tensor(0.3443)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.0.weight tensor(25.8543)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.0649)\n",
      "conv1.2.bias tensor(0.0822)\n",
      "dense1.0.weight tensor(33006.5078)\n",
      "dense1.0.bias tensor(0.3479)\n",
      "dense2.0.weight tensor(90.2953)\n",
      "dense2.0.bias tensor(0.1746)\n",
      "conv1.0.weight tensor(26.2804)\n",
      "conv1.0.bias tensor(0.0003)\n",
      "conv1.2.weight tensor(0.1520)\n",
      "conv1.2.bias tensor(0.1960)\n",
      "dense1.0.weight tensor(32764.2305)\n",
      "dense1.0.bias tensor(0.4351)\n",
      "dense2.0.weight tensor(106.5520)\n",
      "dense2.0.bias tensor(0.2385)\n",
      "conv1.0.weight tensor(11.6593)\n",
      "conv1.0.bias tensor(0.0007)\n",
      "conv1.2.weight tensor(0.1445)\n",
      "conv1.2.bias tensor(0.1432)\n",
      "dense1.0.weight tensor(34815.8164)\n",
      "dense1.0.bias tensor(0.4551)\n",
      "dense2.0.weight tensor(115.9584)\n",
      "dense2.0.bias tensor(0.2461)\n",
      "conv1.0.weight tensor(9.7942)\n",
      "conv1.0.bias tensor(0.0006)\n",
      "conv1.2.weight tensor(0.1529)\n",
      "conv1.2.bias tensor(0.1495)\n",
      "dense1.0.weight tensor(35223.9062)\n",
      "dense1.0.bias tensor(0.4195)\n",
      "dense2.0.weight tensor(107.2742)\n",
      "dense2.0.bias tensor(0.1973)\n",
      "conv1.0.weight tensor(23.7661)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.2003)\n",
      "conv1.2.bias tensor(0.1926)\n",
      "dense1.0.weight tensor(40956.9102)\n",
      "dense1.0.bias tensor(0.4627)\n",
      "dense2.0.weight tensor(123.9818)\n",
      "dense2.0.bias tensor(0.2371)\n",
      "conv1.0.weight tensor(9.5056)\n",
      "conv1.0.bias tensor(0.0006)\n",
      "conv1.2.weight tensor(0.1895)\n",
      "conv1.2.bias tensor(0.2173)\n",
      "dense1.0.weight tensor(27947.4824)\n",
      "dense1.0.bias tensor(0.3401)\n",
      "dense2.0.weight tensor(85.5537)\n",
      "dense2.0.bias tensor(0.1536)\n",
      "conv1.0.weight tensor(33.1054)\n",
      "conv1.0.bias tensor(0.0005)\n",
      "conv1.2.weight tensor(0.0634)\n",
      "conv1.2.bias tensor(0.0745)\n",
      "dense1.0.weight tensor(39315.9844)\n",
      "dense1.0.bias tensor(0.4703)\n",
      "dense2.0.weight tensor(125.4868)\n",
      "dense2.0.bias tensor(0.2312)\n",
      "conv1.0.weight tensor(48.1847)\n",
      "conv1.0.bias tensor(0.0008)\n",
      "conv1.2.weight tensor(0.1486)\n",
      "conv1.2.bias tensor(0.2504)\n",
      "dense1.0.weight tensor(34090.8125)\n",
      "dense1.0.bias tensor(0.4541)\n",
      "dense2.0.weight tensor(100.4666)\n",
      "dense2.0.bias tensor(0.2209)\n",
      "conv1.0.weight tensor(17.7466)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.1523)\n",
      "conv1.2.bias tensor(0.1306)\n",
      "dense1.0.weight tensor(31666.3359)\n",
      "dense1.0.bias tensor(0.3509)\n",
      "dense2.0.weight tensor(92.6591)\n",
      "dense2.0.bias tensor(0.1827)\n",
      "conv1.0.weight tensor(11.5956)\n",
      "conv1.0.bias tensor(0.0008)\n",
      "conv1.2.weight tensor(0.0756)\n",
      "conv1.2.bias tensor(0.0811)\n",
      "dense1.0.weight tensor(37537.8125)\n",
      "dense1.0.bias tensor(0.4805)\n",
      "dense2.0.weight tensor(116.0244)\n",
      "dense2.0.bias tensor(0.2543)\n",
      "conv1.0.weight tensor(17.4819)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.1024)\n",
      "conv1.2.bias tensor(0.0639)\n",
      "dense1.0.weight tensor(32087.4902)\n",
      "dense1.0.bias tensor(0.4160)\n",
      "dense2.0.weight tensor(113.0917)\n",
      "dense2.0.bias tensor(0.2367)\n",
      "conv1.0.weight tensor(14.8274)\n",
      "conv1.0.bias tensor(0.0001)\n",
      "conv1.2.weight tensor(0.1430)\n",
      "conv1.2.bias tensor(0.1784)\n",
      "dense1.0.weight tensor(33418.5547)\n",
      "dense1.0.bias tensor(0.3986)\n",
      "dense2.0.weight tensor(94.5610)\n",
      "dense2.0.bias tensor(0.1878)\n",
      "conv1.0.weight tensor(13.5732)\n",
      "conv1.0.bias tensor(0.0011)\n",
      "conv1.2.weight tensor(0.1189)\n",
      "conv1.2.bias tensor(0.1269)\n",
      "dense1.0.weight tensor(42963.4023)\n",
      "dense1.0.bias tensor(0.5233)\n",
      "dense2.0.weight tensor(133.3938)\n",
      "dense2.0.bias tensor(0.2621)\n",
      "conv1.0.weight tensor(44.2088)\n",
      "conv1.0.bias tensor(0.0009)\n",
      "conv1.2.weight tensor(0.2466)\n",
      "conv1.2.bias tensor(0.2255)\n",
      "dense1.0.weight tensor(44375.9844)\n",
      "dense1.0.bias tensor(0.5793)\n",
      "dense2.0.weight tensor(131.8151)\n",
      "dense2.0.bias tensor(0.2960)\n",
      "conv1.0.weight tensor(22.4059)\n",
      "conv1.0.bias tensor(0.0005)\n",
      "conv1.2.weight tensor(0.2082)\n",
      "conv1.2.bias tensor(0.2067)\n",
      "dense1.0.weight tensor(50046.2070)\n",
      "dense1.0.bias tensor(0.7192)\n",
      "dense2.0.weight tensor(180.1390)\n",
      "dense2.0.bias tensor(0.3847)\n",
      "conv1.0.weight tensor(21.4751)\n",
      "conv1.0.bias tensor(0.0001)\n",
      "conv1.2.weight tensor(0.1056)\n",
      "conv1.2.bias tensor(0.1410)\n",
      "dense1.0.weight tensor(30898.5547)\n",
      "dense1.0.bias tensor(0.3247)\n",
      "dense2.0.weight tensor(88.4593)\n",
      "dense2.0.bias tensor(0.1586)\n",
      "conv1.0.weight tensor(42.2900)\n",
      "conv1.0.bias tensor(0.0012)\n",
      "conv1.2.weight tensor(0.3222)\n",
      "conv1.2.bias tensor(0.3689)\n",
      "dense1.0.weight tensor(39128.9883)\n",
      "dense1.0.bias tensor(0.4528)\n",
      "dense2.0.weight tensor(108.2664)\n",
      "dense2.0.bias tensor(0.1919)\n",
      "conv1.0.weight tensor(25.7967)\n",
      "conv1.0.bias tensor(0.0007)\n",
      "conv1.2.weight tensor(0.2165)\n",
      "conv1.2.bias tensor(0.1879)\n",
      "dense1.0.weight tensor(32858.7695)\n",
      "dense1.0.bias tensor(0.3146)\n",
      "dense2.0.weight tensor(84.1543)\n",
      "dense2.0.bias tensor(0.1434)\n",
      "conv1.0.weight tensor(14.9716)\n",
      "conv1.0.bias tensor(0.0003)\n",
      "conv1.2.weight tensor(0.1761)\n",
      "conv1.2.bias tensor(0.2395)\n",
      "dense1.0.weight tensor(30411.2109)\n",
      "dense1.0.bias tensor(0.3323)\n",
      "dense2.0.weight tensor(88.7059)\n",
      "dense2.0.bias tensor(0.1431)\n",
      "conv1.0.weight tensor(9.6211)\n",
      "conv1.0.bias tensor(0.0003)\n",
      "conv1.2.weight tensor(0.1429)\n",
      "conv1.2.bias tensor(0.1174)\n",
      "dense1.0.weight tensor(37317.5352)\n",
      "dense1.0.bias tensor(0.4095)\n",
      "dense2.0.weight tensor(112.4300)\n",
      "dense2.0.bias tensor(0.2184)\n",
      "conv1.0.weight tensor(35.9506)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.1317)\n",
      "conv1.2.bias tensor(0.1531)\n",
      "dense1.0.weight tensor(38581.9023)\n",
      "dense1.0.bias tensor(0.3712)\n",
      "dense2.0.weight tensor(102.2262)\n",
      "dense2.0.bias tensor(0.1638)\n",
      "conv1.0.weight tensor(39.4213)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.1020)\n",
      "conv1.2.bias tensor(0.1428)\n",
      "dense1.0.weight tensor(36010.4883)\n",
      "dense1.0.bias tensor(0.3662)\n",
      "dense2.0.weight tensor(95.0439)\n",
      "dense2.0.bias tensor(0.1623)\n",
      "conv1.0.weight tensor(18.5680)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.2079)\n",
      "conv1.2.bias tensor(0.2608)\n",
      "dense1.0.weight tensor(41220.8828)\n",
      "dense1.0.bias tensor(0.6061)\n",
      "dense2.0.weight tensor(144.8634)\n",
      "dense2.0.bias tensor(0.3015)\n",
      "conv1.0.weight tensor(19.8212)\n",
      "conv1.0.bias tensor(0.0006)\n",
      "conv1.2.weight tensor(0.2099)\n",
      "conv1.2.bias tensor(0.2374)\n",
      "dense1.0.weight tensor(36011.0625)\n",
      "dense1.0.bias tensor(0.4360)\n",
      "dense2.0.weight tensor(115.0445)\n",
      "dense2.0.bias tensor(0.2058)\n",
      "conv1.0.weight tensor(20.9436)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.1514)\n",
      "conv1.2.bias tensor(0.2389)\n",
      "dense1.0.weight tensor(36920.8984)\n",
      "dense1.0.bias tensor(0.4551)\n",
      "dense2.0.weight tensor(107.2277)\n",
      "dense2.0.bias tensor(0.2115)\n",
      "conv1.0.weight tensor(26.7838)\n",
      "conv1.0.bias tensor(0.0001)\n",
      "conv1.2.weight tensor(0.1689)\n",
      "conv1.2.bias tensor(0.2443)\n",
      "dense1.0.weight tensor(38165.3594)\n",
      "dense1.0.bias tensor(0.5279)\n",
      "dense2.0.weight tensor(138.6244)\n",
      "dense2.0.bias tensor(0.2828)\n",
      "conv1.0.weight tensor(22.2660)\n",
      "conv1.0.bias tensor(0.0008)\n",
      "conv1.2.weight tensor(0.1465)\n",
      "conv1.2.bias tensor(0.2220)\n",
      "dense1.0.weight tensor(33298.3516)\n",
      "dense1.0.bias tensor(0.3895)\n",
      "dense2.0.weight tensor(95.3974)\n",
      "dense2.0.bias tensor(0.1810)\n",
      "conv1.0.weight tensor(13.7705)\n",
      "conv1.0.bias tensor(0.0005)\n",
      "conv1.2.weight tensor(0.1377)\n",
      "conv1.2.bias tensor(0.1398)\n",
      "dense1.0.weight tensor(36594.2266)\n",
      "dense1.0.bias tensor(0.4386)\n",
      "dense2.0.weight tensor(111.0403)\n",
      "dense2.0.bias tensor(0.2190)\n",
      "conv1.0.weight tensor(13.5438)\n",
      "conv1.0.bias tensor(0.0003)\n",
      "conv1.2.weight tensor(0.0862)\n",
      "conv1.2.bias tensor(0.0802)\n",
      "dense1.0.weight tensor(26746.4531)\n",
      "dense1.0.bias tensor(0.3410)\n",
      "dense2.0.weight tensor(82.4383)\n",
      "dense2.0.bias tensor(0.1521)\n",
      "conv1.0.weight tensor(22.3113)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.1385)\n",
      "conv1.2.bias tensor(0.1226)\n",
      "dense1.0.weight tensor(31516.8242)\n",
      "dense1.0.bias tensor(0.3233)\n",
      "dense2.0.weight tensor(79.5814)\n",
      "dense2.0.bias tensor(0.1370)\n",
      "conv1.0.weight tensor(32.9452)\n",
      "conv1.0.bias tensor(0.0006)\n",
      "conv1.2.weight tensor(0.1313)\n",
      "conv1.2.bias tensor(0.0930)\n",
      "dense1.0.weight tensor(35319.5469)\n",
      "dense1.0.bias tensor(0.3850)\n",
      "dense2.0.weight tensor(100.2516)\n",
      "dense2.0.bias tensor(0.1680)\n",
      "conv1.0.weight tensor(37.9288)\n",
      "conv1.0.bias tensor(8.9730e-05)\n",
      "conv1.2.weight tensor(0.1394)\n",
      "conv1.2.bias tensor(0.2414)\n",
      "dense1.0.weight tensor(27020.1211)\n",
      "dense1.0.bias tensor(0.3566)\n",
      "dense2.0.weight tensor(84.7180)\n",
      "dense2.0.bias tensor(0.1625)\n",
      "conv1.0.weight tensor(18.3682)\n",
      "conv1.0.bias tensor(0.0003)\n",
      "conv1.2.weight tensor(0.0984)\n",
      "conv1.2.bias tensor(0.0932)\n",
      "dense1.0.weight tensor(38563.4258)\n",
      "dense1.0.bias tensor(0.5290)\n",
      "dense2.0.weight tensor(108.3934)\n",
      "dense2.0.bias tensor(0.2092)\n",
      "conv1.0.weight tensor(20.4834)\n",
      "conv1.0.bias tensor(0.0003)\n",
      "conv1.2.weight tensor(0.1483)\n",
      "conv1.2.bias tensor(0.1796)\n",
      "dense1.0.weight tensor(37464.1289)\n",
      "dense1.0.bias tensor(0.5387)\n",
      "dense2.0.weight tensor(132.4449)\n",
      "dense2.0.bias tensor(0.2875)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.0.weight tensor(21.4422)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.1374)\n",
      "conv1.2.bias tensor(0.1086)\n",
      "dense1.0.weight tensor(31927.0254)\n",
      "dense1.0.bias tensor(0.4163)\n",
      "dense2.0.weight tensor(115.1787)\n",
      "dense2.0.bias tensor(0.2402)\n",
      "conv1.0.weight tensor(7.5337)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.0900)\n",
      "conv1.2.bias tensor(0.0752)\n",
      "dense1.0.weight tensor(30884.8594)\n",
      "dense1.0.bias tensor(0.3391)\n",
      "dense2.0.weight tensor(95.0450)\n",
      "dense2.0.bias tensor(0.1510)\n",
      "conv1.0.weight tensor(19.4450)\n",
      "conv1.0.bias tensor(0.0003)\n",
      "conv1.2.weight tensor(0.0716)\n",
      "conv1.2.bias tensor(0.0635)\n",
      "dense1.0.weight tensor(28620.1602)\n",
      "dense1.0.bias tensor(0.2838)\n",
      "dense2.0.weight tensor(72.8513)\n",
      "dense2.0.bias tensor(0.1315)\n",
      "conv1.0.weight tensor(41.5038)\n",
      "conv1.0.bias tensor(0.0011)\n",
      "conv1.2.weight tensor(0.1267)\n",
      "conv1.2.bias tensor(0.0752)\n",
      "dense1.0.weight tensor(31349.3477)\n",
      "dense1.0.bias tensor(0.3173)\n",
      "dense2.0.weight tensor(92.1747)\n",
      "dense2.0.bias tensor(0.1428)\n",
      "conv1.0.weight tensor(9.4051)\n",
      "conv1.0.bias tensor(0.0008)\n",
      "conv1.2.weight tensor(0.1221)\n",
      "conv1.2.bias tensor(0.1504)\n",
      "dense1.0.weight tensor(30621.3066)\n",
      "dense1.0.bias tensor(0.3964)\n",
      "dense2.0.weight tensor(104.2843)\n",
      "dense2.0.bias tensor(0.2090)\n",
      "conv1.0.weight tensor(35.1357)\n",
      "conv1.0.bias tensor(0.0003)\n",
      "conv1.2.weight tensor(0.1854)\n",
      "conv1.2.bias tensor(0.3156)\n",
      "dense1.0.weight tensor(38679.8633)\n",
      "dense1.0.bias tensor(0.4880)\n",
      "dense2.0.weight tensor(119.1300)\n",
      "dense2.0.bias tensor(0.2282)\n",
      "conv1.0.weight tensor(21.7648)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.0925)\n",
      "conv1.2.bias tensor(0.1693)\n",
      "dense1.0.weight tensor(32220.1973)\n",
      "dense1.0.bias tensor(0.4866)\n",
      "dense2.0.weight tensor(118.4516)\n",
      "dense2.0.bias tensor(0.2624)\n",
      "conv1.0.weight tensor(18.5779)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.1773)\n",
      "conv1.2.bias tensor(0.2576)\n",
      "dense1.0.weight tensor(33004.7656)\n",
      "dense1.0.bias tensor(0.4827)\n",
      "dense2.0.weight tensor(121.8218)\n",
      "dense2.0.bias tensor(0.2374)\n",
      "conv1.0.weight tensor(22.7227)\n",
      "conv1.0.bias tensor(0.0005)\n",
      "conv1.2.weight tensor(0.1679)\n",
      "conv1.2.bias tensor(0.1611)\n",
      "dense1.0.weight tensor(34671.4219)\n",
      "dense1.0.bias tensor(0.4066)\n",
      "dense2.0.weight tensor(97.7393)\n",
      "dense2.0.bias tensor(0.1744)\n",
      "conv1.0.weight tensor(31.2568)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.0691)\n",
      "conv1.2.bias tensor(0.1239)\n",
      "dense1.0.weight tensor(30053.8262)\n",
      "dense1.0.bias tensor(0.3544)\n",
      "dense2.0.weight tensor(87.4727)\n",
      "dense2.0.bias tensor(0.1512)\n",
      "conv1.0.weight tensor(17.6319)\n",
      "conv1.0.bias tensor(0.0003)\n",
      "conv1.2.weight tensor(0.2785)\n",
      "conv1.2.bias tensor(0.3177)\n",
      "dense1.0.weight tensor(39997.5938)\n",
      "dense1.0.bias tensor(0.4476)\n",
      "dense2.0.weight tensor(109.6691)\n",
      "dense2.0.bias tensor(0.1809)\n",
      "conv1.0.weight tensor(17.8617)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.1015)\n",
      "conv1.2.bias tensor(0.1052)\n",
      "dense1.0.weight tensor(32590.7266)\n",
      "dense1.0.bias tensor(0.3427)\n",
      "dense2.0.weight tensor(100.3502)\n",
      "dense2.0.bias tensor(0.1609)\n",
      "conv1.0.weight tensor(15.0331)\n",
      "conv1.0.bias tensor(0.0005)\n",
      "conv1.2.weight tensor(0.2640)\n",
      "conv1.2.bias tensor(0.3168)\n",
      "dense1.0.weight tensor(43579.1172)\n",
      "dense1.0.bias tensor(0.5224)\n",
      "dense2.0.weight tensor(142.9902)\n",
      "dense2.0.bias tensor(0.2402)\n",
      "conv1.0.weight tensor(15.3548)\n",
      "conv1.0.bias tensor(0.0005)\n",
      "conv1.2.weight tensor(0.1465)\n",
      "conv1.2.bias tensor(0.1293)\n",
      "dense1.0.weight tensor(29886.5508)\n",
      "dense1.0.bias tensor(0.3515)\n",
      "dense2.0.weight tensor(87.4582)\n",
      "dense2.0.bias tensor(0.1644)\n",
      "conv1.0.weight tensor(30.1358)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.2231)\n",
      "conv1.2.bias tensor(0.1962)\n",
      "dense1.0.weight tensor(43126.8008)\n",
      "dense1.0.bias tensor(0.5538)\n",
      "dense2.0.weight tensor(129.5782)\n",
      "dense2.0.bias tensor(0.2450)\n",
      "conv1.0.weight tensor(24.6249)\n",
      "conv1.0.bias tensor(0.0007)\n",
      "conv1.2.weight tensor(0.2188)\n",
      "conv1.2.bias tensor(0.2649)\n",
      "dense1.0.weight tensor(33223.2188)\n",
      "dense1.0.bias tensor(0.3826)\n",
      "dense2.0.weight tensor(118.9807)\n",
      "dense2.0.bias tensor(0.2074)\n",
      "conv1.0.weight tensor(36.6895)\n",
      "conv1.0.bias tensor(0.0011)\n",
      "conv1.2.weight tensor(0.1285)\n",
      "conv1.2.bias tensor(0.1884)\n",
      "dense1.0.weight tensor(30418.5664)\n",
      "dense1.0.bias tensor(0.3132)\n",
      "dense2.0.weight tensor(100.2478)\n",
      "dense2.0.bias tensor(0.1733)\n",
      "conv1.0.weight tensor(32.1327)\n",
      "conv1.0.bias tensor(0.0005)\n",
      "conv1.2.weight tensor(0.1696)\n",
      "conv1.2.bias tensor(0.1825)\n",
      "dense1.0.weight tensor(39377.6367)\n",
      "dense1.0.bias tensor(0.4441)\n",
      "dense2.0.weight tensor(119.4371)\n",
      "dense2.0.bias tensor(0.2024)\n",
      "conv1.0.weight tensor(38.7627)\n",
      "conv1.0.bias tensor(0.0006)\n",
      "conv1.2.weight tensor(0.1084)\n",
      "conv1.2.bias tensor(0.1576)\n",
      "dense1.0.weight tensor(31733.0820)\n",
      "dense1.0.bias tensor(0.3543)\n",
      "dense2.0.weight tensor(103.9675)\n",
      "dense2.0.bias tensor(0.1669)\n",
      "conv1.0.weight tensor(18.4847)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.1455)\n",
      "conv1.2.bias tensor(0.1918)\n",
      "dense1.0.weight tensor(35318.8281)\n",
      "dense1.0.bias tensor(0.4487)\n",
      "dense2.0.weight tensor(140.1314)\n",
      "dense2.0.bias tensor(0.2482)\n",
      "conv1.0.weight tensor(31.5351)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.1652)\n",
      "conv1.2.bias tensor(0.2149)\n",
      "dense1.0.weight tensor(37708.6094)\n",
      "dense1.0.bias tensor(0.4622)\n",
      "dense2.0.weight tensor(125.4067)\n",
      "dense2.0.bias tensor(0.2072)\n",
      "conv1.0.weight tensor(12.2731)\n",
      "conv1.0.bias tensor(9.9433e-05)\n",
      "conv1.2.weight tensor(0.1769)\n",
      "conv1.2.bias tensor(0.2004)\n",
      "dense1.0.weight tensor(38081.4375)\n",
      "dense1.0.bias tensor(0.4560)\n",
      "dense2.0.weight tensor(127.4757)\n",
      "dense2.0.bias tensor(0.2363)\n",
      "conv1.0.weight tensor(41.2650)\n",
      "conv1.0.bias tensor(0.0011)\n",
      "conv1.2.weight tensor(0.1681)\n",
      "conv1.2.bias tensor(0.1676)\n",
      "dense1.0.weight tensor(33664.2773)\n",
      "dense1.0.bias tensor(0.3045)\n",
      "dense2.0.weight tensor(109.8535)\n",
      "dense2.0.bias tensor(0.1507)\n",
      "conv1.0.weight tensor(44.9574)\n",
      "conv1.0.bias tensor(0.0006)\n",
      "conv1.2.weight tensor(0.2295)\n",
      "conv1.2.bias tensor(0.3367)\n",
      "dense1.0.weight tensor(39505.6797)\n",
      "dense1.0.bias tensor(0.5657)\n",
      "dense2.0.weight tensor(135.5922)\n",
      "dense2.0.bias tensor(0.2673)\n",
      "conv1.0.weight tensor(56.6165)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.1718)\n",
      "conv1.2.bias tensor(0.1127)\n",
      "dense1.0.weight tensor(41294.0547)\n",
      "dense1.0.bias tensor(0.5474)\n",
      "dense2.0.weight tensor(144.2378)\n",
      "dense2.0.bias tensor(0.2710)\n",
      "conv1.0.weight tensor(24.3760)\n",
      "conv1.0.bias tensor(0.0005)\n",
      "conv1.2.weight tensor(0.2074)\n",
      "conv1.2.bias tensor(0.2521)\n",
      "dense1.0.weight tensor(36706.0312)\n",
      "dense1.0.bias tensor(0.3484)\n",
      "dense2.0.weight tensor(107.7717)\n",
      "dense2.0.bias tensor(0.1581)\n",
      "conv1.0.weight tensor(25.3099)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.1453)\n",
      "conv1.2.bias tensor(0.1271)\n",
      "dense1.0.weight tensor(34252.5391)\n",
      "dense1.0.bias tensor(0.4018)\n",
      "dense2.0.weight tensor(124.1883)\n",
      "dense2.0.bias tensor(0.1887)\n",
      "conv1.0.weight tensor(19.2213)\n",
      "conv1.0.bias tensor(0.0011)\n",
      "conv1.2.weight tensor(0.0692)\n",
      "conv1.2.bias tensor(0.0831)\n",
      "dense1.0.weight tensor(39370.2227)\n",
      "dense1.0.bias tensor(0.5218)\n",
      "dense2.0.weight tensor(137.0341)\n",
      "dense2.0.bias tensor(0.2379)\n",
      "conv1.0.weight tensor(31.8608)\n",
      "conv1.0.bias tensor(0.0010)\n",
      "conv1.2.weight tensor(0.2602)\n",
      "conv1.2.bias tensor(0.2509)\n",
      "dense1.0.weight tensor(40186.2891)\n",
      "dense1.0.bias tensor(0.5361)\n",
      "dense2.0.weight tensor(150.6464)\n",
      "dense2.0.bias tensor(0.2553)\n",
      "conv1.0.weight tensor(40.2214)\n",
      "conv1.0.bias tensor(0.0009)\n",
      "conv1.2.weight tensor(0.1766)\n",
      "conv1.2.bias tensor(0.2301)\n",
      "dense1.0.weight tensor(39321.8672)\n",
      "dense1.0.bias tensor(0.5287)\n",
      "dense2.0.weight tensor(148.9452)\n",
      "dense2.0.bias tensor(0.2691)\n",
      "conv1.0.weight tensor(14.4556)\n",
      "conv1.0.bias tensor(0.0003)\n",
      "conv1.2.weight tensor(0.1461)\n",
      "conv1.2.bias tensor(0.0928)\n",
      "dense1.0.weight tensor(33182.2578)\n",
      "dense1.0.bias tensor(0.4037)\n",
      "dense2.0.weight tensor(113.8057)\n",
      "dense2.0.bias tensor(0.1823)\n",
      "conv1.0.weight tensor(20.7432)\n",
      "conv1.0.bias tensor(0.0008)\n",
      "conv1.2.weight tensor(0.1871)\n",
      "conv1.2.bias tensor(0.2532)\n",
      "dense1.0.weight tensor(42694.2305)\n",
      "dense1.0.bias tensor(0.5317)\n",
      "dense2.0.weight tensor(146.2691)\n",
      "dense2.0.bias tensor(0.2360)\n",
      "conv1.0.weight tensor(26.1467)\n",
      "conv1.0.bias tensor(0.0013)\n",
      "conv1.2.weight tensor(0.1715)\n",
      "conv1.2.bias tensor(0.1508)\n",
      "dense1.0.weight tensor(37501.2031)\n",
      "dense1.0.bias tensor(0.4218)\n",
      "dense2.0.weight tensor(130.4837)\n",
      "dense2.0.bias tensor(0.2303)\n",
      "conv1.0.weight tensor(17.4035)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.1726)\n",
      "conv1.2.bias tensor(0.1679)\n",
      "dense1.0.weight tensor(33035.8789)\n",
      "dense1.0.bias tensor(0.3851)\n",
      "dense2.0.weight tensor(113.4519)\n",
      "dense2.0.bias tensor(0.1860)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.0.weight tensor(23.6515)\n",
      "conv1.0.bias tensor(0.0008)\n",
      "conv1.2.weight tensor(0.1320)\n",
      "conv1.2.bias tensor(0.1824)\n",
      "dense1.0.weight tensor(37788.7422)\n",
      "dense1.0.bias tensor(0.4440)\n",
      "dense2.0.weight tensor(134.4448)\n",
      "dense2.0.bias tensor(0.2220)\n",
      "conv1.0.weight tensor(12.1948)\n",
      "conv1.0.bias tensor(0.0005)\n",
      "conv1.2.weight tensor(0.2904)\n",
      "conv1.2.bias tensor(0.3534)\n",
      "dense1.0.weight tensor(41405.7031)\n",
      "dense1.0.bias tensor(0.5059)\n",
      "dense2.0.weight tensor(155.7048)\n",
      "dense2.0.bias tensor(0.2530)\n",
      "conv1.0.weight tensor(12.1966)\n",
      "conv1.0.bias tensor(0.0005)\n",
      "conv1.2.weight tensor(0.1255)\n",
      "conv1.2.bias tensor(0.1321)\n",
      "dense1.0.weight tensor(38118.6602)\n",
      "dense1.0.bias tensor(0.4443)\n",
      "dense2.0.weight tensor(150.7220)\n",
      "dense2.0.bias tensor(0.2252)\n",
      "conv1.0.weight tensor(18.7935)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.1767)\n",
      "conv1.2.bias tensor(0.1795)\n",
      "dense1.0.weight tensor(29561.2617)\n",
      "dense1.0.bias tensor(0.3462)\n",
      "dense2.0.weight tensor(100.2989)\n",
      "dense2.0.bias tensor(0.1748)\n",
      "conv1.0.weight tensor(29.8182)\n",
      "conv1.0.bias tensor(0.0005)\n",
      "conv1.2.weight tensor(0.1764)\n",
      "conv1.2.bias tensor(0.2680)\n",
      "dense1.0.weight tensor(36834.0586)\n",
      "dense1.0.bias tensor(0.4582)\n",
      "dense2.0.weight tensor(133.1672)\n",
      "dense2.0.bias tensor(0.2282)\n",
      "conv1.0.weight tensor(16.8988)\n",
      "conv1.0.bias tensor(0.0003)\n",
      "conv1.2.weight tensor(0.1285)\n",
      "conv1.2.bias tensor(0.0959)\n",
      "dense1.0.weight tensor(24430.2207)\n",
      "dense1.0.bias tensor(0.2986)\n",
      "dense2.0.weight tensor(83.3242)\n",
      "dense2.0.bias tensor(0.1371)\n",
      "conv1.0.weight tensor(7.8440)\n",
      "conv1.0.bias tensor(0.0001)\n",
      "conv1.2.weight tensor(0.1862)\n",
      "conv1.2.bias tensor(0.2869)\n",
      "dense1.0.weight tensor(32307.4180)\n",
      "dense1.0.bias tensor(0.3851)\n",
      "dense2.0.weight tensor(93.4960)\n",
      "dense2.0.bias tensor(0.1460)\n",
      "conv1.0.weight tensor(17.4732)\n",
      "conv1.0.bias tensor(0.0004)\n",
      "conv1.2.weight tensor(0.1558)\n",
      "conv1.2.bias tensor(0.1756)\n",
      "dense1.0.weight tensor(32046.7930)\n",
      "dense1.0.bias tensor(0.4038)\n",
      "dense2.0.weight tensor(120.0040)\n",
      "dense2.0.bias tensor(0.1916)\n",
      "conv1.0.weight tensor(26.5957)\n",
      "conv1.0.bias tensor(0.0010)\n",
      "conv1.2.weight tensor(0.1797)\n",
      "conv1.2.bias tensor(0.2029)\n",
      "dense1.0.weight tensor(35679.2344)\n",
      "dense1.0.bias tensor(0.4212)\n",
      "dense2.0.weight tensor(117.4251)\n",
      "dense2.0.bias tensor(0.2076)\n",
      "conv1.0.weight tensor(17.1823)\n",
      "conv1.0.bias tensor(0.0011)\n",
      "conv1.2.weight tensor(0.0903)\n",
      "conv1.2.bias tensor(0.0819)\n",
      "dense1.0.weight tensor(33576.8203)\n",
      "dense1.0.bias tensor(0.3915)\n",
      "dense2.0.weight tensor(104.5789)\n",
      "dense2.0.bias tensor(0.1713)\n",
      "conv1.0.weight tensor(23.3721)\n",
      "conv1.0.bias tensor(0.0008)\n",
      "conv1.2.weight tensor(0.0882)\n",
      "conv1.2.bias tensor(0.1334)\n",
      "dense1.0.weight tensor(30874.7695)\n",
      "dense1.0.bias tensor(0.3825)\n",
      "dense2.0.weight tensor(111.8318)\n",
      "dense2.0.bias tensor(0.1961)\n",
      "conv1.0.weight tensor(13.2930)\n",
      "conv1.0.bias tensor(0.0013)\n",
      "conv1.2.weight tensor(0.1182)\n",
      "conv1.2.bias tensor(0.1604)\n",
      "dense1.0.weight tensor(35214.6250)\n",
      "dense1.0.bias tensor(0.4527)\n",
      "dense2.0.weight tensor(123.9485)\n",
      "dense2.0.bias tensor(0.2350)\n",
      "conv1.0.weight tensor(19.8000)\n",
      "conv1.0.bias tensor(0.0006)\n",
      "conv1.2.weight tensor(0.2741)\n",
      "conv1.2.bias tensor(0.2480)\n",
      "dense1.0.weight tensor(38795.3438)\n",
      "dense1.0.bias tensor(0.4598)\n",
      "dense2.0.weight tensor(152.6768)\n",
      "dense2.0.bias tensor(0.2576)\n",
      "conv1.0.weight tensor(37.4769)\n",
      "conv1.0.bias tensor(0.0014)\n",
      "conv1.2.weight tensor(0.1352)\n",
      "conv1.2.bias tensor(0.2383)\n",
      "dense1.0.weight tensor(39174.4727)\n",
      "dense1.0.bias tensor(0.4568)\n",
      "dense2.0.weight tensor(146.9215)\n",
      "dense2.0.bias tensor(0.2272)\n",
      "conv1.0.weight tensor(15.2588)\n",
      "conv1.0.bias tensor(0.0003)\n",
      "conv1.2.weight tensor(0.2093)\n",
      "conv1.2.bias tensor(0.2853)\n",
      "dense1.0.weight tensor(37616.8086)\n",
      "dense1.0.bias tensor(0.4849)\n",
      "dense2.0.weight tensor(140.3690)\n",
      "dense2.0.bias tensor(0.2497)\n",
      "conv1.0.weight tensor(14.1891)\n",
      "conv1.0.bias tensor(0.0007)\n",
      "conv1.2.weight tensor(0.0939)\n",
      "conv1.2.bias tensor(0.1083)\n",
      "dense1.0.weight tensor(33712.3203)\n",
      "dense1.0.bias tensor(0.3898)\n",
      "dense2.0.weight tensor(133.3674)\n",
      "dense2.0.bias tensor(0.2184)\n",
      "conv1.0.weight tensor(16.5504)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.1942)\n",
      "conv1.2.bias tensor(0.2047)\n",
      "dense1.0.weight tensor(39498.1133)\n",
      "dense1.0.bias tensor(0.4628)\n",
      "dense2.0.weight tensor(143.2351)\n",
      "dense2.0.bias tensor(0.2248)\n",
      "conv1.0.weight tensor(25.8050)\n",
      "conv1.0.bias tensor(0.0010)\n",
      "conv1.2.weight tensor(0.1772)\n",
      "conv1.2.bias tensor(0.1825)\n",
      "dense1.0.weight tensor(46357.1875)\n",
      "dense1.0.bias tensor(0.5416)\n",
      "dense2.0.weight tensor(168.2925)\n",
      "dense2.0.bias tensor(0.2674)\n",
      "conv1.0.weight tensor(18.1724)\n",
      "conv1.0.bias tensor(0.0002)\n",
      "conv1.2.weight tensor(0.1465)\n",
      "conv1.2.bias tensor(0.1196)\n",
      "dense1.0.weight tensor(30570.5059)\n",
      "dense1.0.bias tensor(0.3709)\n",
      "dense2.0.weight tensor(112.8849)\n",
      "dense2.0.bias tensor(0.1926)\n",
      "conv1.0.weight tensor(45.5551)\n",
      "conv1.0.bias tensor(5.3679e-05)\n",
      "conv1.2.weight tensor(0.5600)\n",
      "conv1.2.bias tensor(0.6097)\n",
      "dense1.0.weight tensor(50700.4062)\n",
      "dense1.0.bias tensor(0.7621)\n",
      "dense2.0.weight tensor(177.8867)\n",
      "dense2.0.bias tensor(0.2970)\n",
      "Time taken: 262.9286549091339\n"
     ]
    }
   ],
   "source": [
    "model.train()    # set the model in training mode coz the batchnorm layer behaves differently when using in eval mode.\n",
    "num_epochs = 2\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    for images, labels in train_r1_loader:\n",
    "        out = model(images.float())\n",
    "        loss = loss_function(out,labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        for name, param in model.named_parameters():         # this is just to check if the parameters are getting valid gradients\n",
    "            print(name, param.grad.abs().sum())\n",
    "    \n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "    \n",
    "end = time.time()\n",
    "print('Time taken: {}'.format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "43a5ad52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 37])\n",
      "tensor([[-3.1791, -3.6489, -3.6489,  ..., -3.6489, -3.6489, -3.6489],\n",
      "        [-3.6871, -2.8780, -3.6871,  ..., -3.4649, -3.6871, -3.6871],\n",
      "        [-3.7575, -3.7575, -3.7575,  ..., -3.0119, -3.7575, -3.7575],\n",
      "        ...,\n",
      "        [-3.9416, -3.9416, -3.9416,  ..., -3.9416, -3.9416, -3.9416],\n",
      "        [-3.6606, -3.2834, -3.6606,  ..., -3.6606, -3.6606, -3.6606],\n",
      "        [-3.6903, -2.9969, -3.6903,  ..., -3.1430, -3.6903, -3.6903]])\n",
      "tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False,  True,\n",
      "        False, False, False, False, False, False, False, False, False,  True,\n",
      "        False, False, False, False, False, False,  True, False, False, False,\n",
      "        False, False,  True, False, False,  True, False, False, False, False,\n",
      "        False, False, False, False])\n",
      "torch.Size([64, 37])\n",
      "tensor([[-3.8843, -3.5386, -3.8843,  ..., -3.5516, -3.8843, -3.8843],\n",
      "        [-3.6697, -3.5021, -3.6697,  ..., -3.5454, -3.6697, -3.6697],\n",
      "        [-3.7075, -2.6234, -3.7075,  ..., -3.7075, -3.7075, -3.7075],\n",
      "        ...,\n",
      "        [-3.6399, -3.0829, -3.6399,  ..., -3.4404, -3.6399, -3.6399],\n",
      "        [-3.6600, -3.1622, -3.6600,  ..., -3.6600, -3.6600, -3.6600],\n",
      "        [-3.8776, -2.6054, -3.8776,  ..., -3.8776, -3.8776, -3.8776]])\n",
      "tensor([False, False, False, False, False,  True, False,  True, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False,  True, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False,  True, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False])\n",
      "torch.Size([64, 37])\n",
      "tensor([[-3.3893, -2.8423, -3.8066,  ..., -3.3148, -3.8066, -3.8066],\n",
      "        [-3.6195, -3.6195, -3.6195,  ..., -3.6195, -3.6195, -3.6195],\n",
      "        [-3.7058, -3.5801, -3.7058,  ..., -3.7058, -3.7058, -3.7058],\n",
      "        ...,\n",
      "        [-3.7546, -3.7546, -3.7546,  ..., -2.9810, -3.7546, -3.7546],\n",
      "        [-4.9617, -4.9617, -4.9617,  ..., -2.3842, -4.9617, -4.9617],\n",
      "        [-3.6391, -3.6391, -3.6391,  ..., -3.4897, -3.6391, -3.6391]])\n",
      "tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False, False, False,\n",
      "         True, False, False, False, False, False, False, False, False, False,\n",
      "        False,  True, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False,  True, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False])\n",
      "torch.Size([64, 37])\n",
      "tensor([[-3.6297, -3.5567, -3.6297,  ..., -3.4788, -3.6297, -3.6297],\n",
      "        [-4.4378, -4.4378, -4.4378,  ..., -2.8827, -4.4378, -4.4378],\n",
      "        [-3.6303, -3.3167, -3.6303,  ..., -3.4274, -3.6303, -3.6303],\n",
      "        ...,\n",
      "        [-3.6626, -3.2079, -3.7924,  ..., -3.7924, -3.7924, -3.7924],\n",
      "        [-3.7649, -3.7612, -3.7649,  ..., -3.1806, -3.7649, -3.7649],\n",
      "        [-3.7681, -3.7681, -3.7681,  ..., -2.6435, -3.7681, -3.7681]])\n",
      "tensor([False, False, False, False, False, False, False, False,  True, False,\n",
      "        False, False, False, False,  True, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False,  True, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False])\n",
      "torch.Size([64, 37])\n",
      "tensor([[-3.6620, -3.5022, -3.6620,  ..., -3.6620, -3.6620, -3.6620],\n",
      "        [-3.6563, -2.7301, -3.6563,  ..., -3.6563, -3.6563, -3.6563],\n",
      "        [-3.7763, -2.9881, -3.7763,  ..., -3.7763, -3.7763, -3.7763],\n",
      "        ...,\n",
      "        [-4.4744, -4.4744, -4.4744,  ..., -2.9029, -4.4744, -4.4744],\n",
      "        [-3.7120, -3.2515, -3.7120,  ..., -3.7120, -3.7120, -3.7120],\n",
      "        [-3.6370, -3.5828, -3.6370,  ..., -3.6370, -3.6370, -3.6370]])\n",
      "tensor([False, False, False,  True, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False,  True,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False,  True, False, False, False,\n",
      "         True, False, False, False, False, False,  True, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False,  True, False, False])\n",
      "torch.Size([64, 37])\n",
      "tensor([[-3.8011, -3.8011, -3.8011,  ..., -2.8731, -3.8011, -3.8011],\n",
      "        [-3.6622, -3.2632, -3.6622,  ..., -3.0555, -3.6622, -3.6622],\n",
      "        [-3.8070, -2.9374, -3.8070,  ..., -3.8070, -3.8070, -3.8070],\n",
      "        ...,\n",
      "        [-3.2704, -3.8292, -3.8292,  ..., -3.8292, -3.8292, -3.8292],\n",
      "        [-3.9832, -3.4470, -3.9832,  ..., -2.7108, -3.9832, -3.9832],\n",
      "        [-4.5100, -4.5100, -4.5100,  ..., -3.8645, -4.5100, -4.5100]])\n",
      "tensor([False, False, False, False, False, False, False, False, False,  True,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False, False, False, False, False,\n",
      "        False, False, False,  True])\n",
      "torch.Size([64, 37])\n",
      "tensor([[-3.7124, -3.1811, -3.7124,  ..., -2.9198, -3.7124, -3.7124],\n",
      "        [-4.1767, -4.1767, -4.1767,  ..., -3.2603, -4.1767, -4.1767],\n",
      "        [-3.8198, -3.1256, -3.8198,  ..., -3.8198, -3.8198, -3.8198],\n",
      "        ...,\n",
      "        [-3.7418, -3.7418, -3.7418,  ..., -2.7848, -3.7418, -3.7418],\n",
      "        [-4.0328, -4.0328, -4.0328,  ..., -2.5208, -4.0328, -4.0328],\n",
      "        [-3.6280, -3.4044, -3.6280,  ..., -3.6280, -3.6280, -3.6280]])\n",
      "tensor([False, False, False, False, False, False, False,  True, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False, False,  True,\n",
      "        False, False, False, False, False, False, False,  True, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False,  True, False, False, False,\n",
      "        False, False, False, False])\n",
      "torch.Size([64, 37])\n",
      "tensor([[-3.8426, -3.3534, -3.8426,  ..., -3.7092, -3.8426, -3.8426],\n",
      "        [-3.8594, -3.8594, -3.8594,  ..., -2.6997, -3.8594, -3.8594],\n",
      "        [-3.8412, -3.8412, -3.8412,  ..., -3.0051, -3.8412, -3.8412],\n",
      "        ...,\n",
      "        [-3.6476, -3.6476, -3.6476,  ..., -3.5777, -3.6476, -3.6476],\n",
      "        [-3.7413, -3.7413, -3.7413,  ..., -2.7330, -3.7413, -3.7413],\n",
      "        [-3.7094, -2.7219, -3.7094,  ..., -3.7094, -3.7094, -3.7094]])\n",
      "tensor([ True, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False,  True, False,  True, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False,  True, False, False,\n",
      "        False, False, False, False, False,  True, False, False, False, False,\n",
      "         True, False, False, False,  True, False, False, False, False, False,\n",
      "        False,  True, False, False])\n",
      "torch.Size([64, 37])\n",
      "tensor([[-3.7900, -2.3197, -3.7900,  ..., -3.7900, -3.7900, -3.7900],\n",
      "        [-3.5666, -3.6892, -3.6892,  ..., -3.1644, -3.6892, -3.6892],\n",
      "        [-3.9058, -3.7399, -3.9058,  ..., -2.9469, -3.9058, -3.9058],\n",
      "        ...,\n",
      "        [-3.7719, -3.0969, -3.7719,  ..., -3.7719, -3.7719, -3.7719],\n",
      "        [-3.7715, -2.0035, -3.7715,  ..., -3.7715, -3.7715, -3.7715],\n",
      "        [-3.6956, -3.3660, -3.6956,  ..., -3.4908, -3.6956, -3.6956]])\n",
      "tensor([False, False, False, False, False, False, False,  True, False, False,\n",
      "        False,  True, False, False, False, False, False, False, False, False,\n",
      "        False,  True, False, False, False, False, False, False,  True, False,\n",
      "         True, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False,  True,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 37])\n",
      "tensor([[-3.7396, -3.7396, -3.7396,  ..., -3.5832, -3.7396, -3.7396],\n",
      "        [-3.8796, -3.0407, -3.8796,  ..., -2.6993, -3.8796, -3.8796],\n",
      "        [-3.6134, -3.6134, -3.6134,  ..., -3.6134, -3.6134, -3.6134],\n",
      "        ...,\n",
      "        [-3.8346, -2.5754, -3.8346,  ..., -2.9810, -3.8346, -3.8346],\n",
      "        [-3.7461, -3.7352, -3.7461,  ..., -2.7076, -3.7461, -3.7461],\n",
      "        [-3.9877, -3.9877, -3.9877,  ..., -3.4358, -3.9877, -3.9877]])\n",
      "tensor([False,  True, False, False, False, False, False, False, False,  True,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False, False, False, False, False,\n",
      "         True, False,  True,  True])\n",
      "torch.Size([64, 37])\n",
      "tensor([[-3.7031, -3.7031, -3.7031,  ..., -3.2935, -3.7031, -3.7031],\n",
      "        [-3.7569, -3.3973, -3.7569,  ..., -3.7569, -3.7569, -3.7569],\n",
      "        [-3.7088, -3.1586, -3.7088,  ..., -3.7088, -3.7088, -3.7088],\n",
      "        ...,\n",
      "        [-3.7886, -1.7976, -3.7886,  ..., -3.7886, -3.7886, -3.7886],\n",
      "        [-3.6409, -3.2028, -3.6409,  ..., -3.6409, -3.6409, -3.6409],\n",
      "        [-3.6290, -3.6290, -3.6290,  ..., -3.4816, -3.6290, -3.6290]])\n",
      "tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "         True, False,  True, False, False, False, False, False, False, False,\n",
      "         True, False,  True, False,  True,  True, False, False, False, False,\n",
      "        False,  True, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False,  True,  True, False, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False, False, False,\n",
      "        False, False, False, False])\n",
      "torch.Size([64, 37])\n",
      "tensor([[-4.6860, -4.6860, -4.6860,  ..., -3.9049, -4.6860, -4.6860],\n",
      "        [-3.7810, -2.7682, -3.7810,  ..., -3.6669, -3.7810, -3.7810],\n",
      "        [-3.7864, -3.4569, -3.7864,  ..., -2.9079, -3.7864, -3.7864],\n",
      "        ...,\n",
      "        [-3.7190, -2.4535, -3.7190,  ..., -3.7190, -3.7190, -3.7190],\n",
      "        [-5.1001, -5.1001, -5.1001,  ..., -3.2120, -5.1001, -5.1001],\n",
      "        [-3.6346, -3.2707, -3.6346,  ..., -3.6346, -3.6346, -3.6346]])\n",
      "tensor([False, False, False, False, False, False, False, False, False,  True,\n",
      "         True, False,  True, False,  True, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False,  True, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False, False, False,\n",
      "        False, False,  True, False])\n",
      "torch.Size([64, 37])\n",
      "tensor([[-3.6682, -3.5911, -3.6682,  ..., -2.9821, -3.6682, -3.6682],\n",
      "        [-3.8277, -3.7391, -3.8277,  ..., -3.3425, -3.8277, -3.8277],\n",
      "        [-3.7157, -3.7157, -3.7157,  ..., -3.2340, -3.7157, -3.7157],\n",
      "        ...,\n",
      "        [-3.7834, -3.5826, -3.7834,  ..., -2.8373, -3.7834, -3.7834],\n",
      "        [-3.6546, -3.1771, -3.6546,  ..., -3.5798, -3.6546, -3.6546],\n",
      "        [-4.0925, -3.7960, -4.0925,  ..., -2.9578, -4.0925, -4.0925]])\n",
      "tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False,  True, False, False, False,  True, False, False,\n",
      "        False, False, False, False, False, False,  True,  True, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False])\n",
      "torch.Size([64, 37])\n",
      "tensor([[-4.2228, -4.2228, -4.2228,  ..., -2.6311, -4.2228, -4.2228],\n",
      "        [-3.6659, -3.3197, -3.6659,  ..., -3.6373, -3.6659, -3.6659],\n",
      "        [-3.7414, -3.3329, -3.7414,  ..., -3.3132, -3.7414, -3.7414],\n",
      "        ...,\n",
      "        [-3.6582, -3.4971, -3.6582,  ..., -3.6582, -3.6582, -3.6582],\n",
      "        [-3.9969, -3.9969, -3.9969,  ..., -3.0614, -3.9969, -3.9969],\n",
      "        [-4.7802, -4.7802, -4.7802,  ..., -3.2451, -4.7802, -4.7802]])\n",
      "tensor([False,  True, False,  True, False, False, False, False, False, False,\n",
      "        False,  True,  True, False, False, False, False, False,  True, False,\n",
      "        False, False,  True, False, False, False, False, False, False, False,\n",
      "        False,  True, False, False, False, False, False, False,  True, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "         True, False,  True, False, False, False, False, False, False, False,\n",
      "         True, False, False,  True])\n",
      "torch.Size([64, 37])\n",
      "tensor([[-3.6870, -3.6870, -3.6870,  ..., -3.1196, -3.6870, -3.6870],\n",
      "        [-3.6661, -3.1670, -3.6661,  ..., -3.1909, -3.6661, -3.6661],\n",
      "        [-3.7175, -2.8980, -3.7175,  ..., -3.3066, -3.7175, -3.7175],\n",
      "        ...,\n",
      "        [-4.4915, -4.4915, -4.4915,  ..., -2.7061, -4.4915, -4.4915],\n",
      "        [-3.1882, -3.7387, -3.7387,  ..., -3.3563, -3.7387, -3.7387],\n",
      "        [-3.8010, -3.8010, -3.8010,  ..., -2.7813, -3.8010, -3.8010]])\n",
      "tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False, False, False,\n",
      "         True, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False,  True,  True, False,  True,\n",
      "        False, False, False, False, False, False, False, False,  True,  True,\n",
      "        False, False, False, False])\n",
      "torch.Size([64, 37])\n",
      "tensor([[-4.3854, -4.3854, -4.3854,  ..., -3.5093, -4.3854, -4.3854],\n",
      "        [-3.8187, -2.7659, -3.8187,  ..., -3.8187, -3.8187, -3.8187],\n",
      "        [-4.2800, -4.2800, -4.2800,  ..., -2.5803, -4.2800, -4.2800],\n",
      "        ...,\n",
      "        [-3.6436, -2.9522, -3.6436,  ..., -3.6436, -3.6436, -3.6436],\n",
      "        [-3.7786, -3.5617, -3.7786,  ..., -2.8475, -3.7786, -3.7786],\n",
      "        [-3.7376, -3.1806, -3.7376,  ..., -2.7299, -3.7376, -3.7376]])\n",
      "tensor([ True,  True, False,  True,  True, False, False, False, False, False,\n",
      "        False, False, False,  True, False, False,  True, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False])\n",
      "torch.Size([64, 37])\n",
      "tensor([[-3.7734, -2.4834, -3.7734,  ..., -2.9959, -3.7734, -3.7734],\n",
      "        [-3.9457, -3.9457, -3.9457,  ..., -3.1531, -3.9457, -3.9457],\n",
      "        [-4.6450, -4.6288, -4.6450,  ..., -2.9033, -4.6450, -4.6450],\n",
      "        ...,\n",
      "        [-4.6407, -4.6407, -4.6407,  ..., -3.4081, -4.6407, -4.6407],\n",
      "        [-3.6644, -2.5593, -3.6644,  ..., -3.6522, -3.6644, -3.6644],\n",
      "        [-3.7865, -3.7865, -3.7865,  ..., -3.3462, -3.7865, -3.7865]])\n",
      "tensor([False, False,  True,  True, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False,  True, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False,  True,  True,  True, False,  True,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False,  True, False,\n",
      "        False, False, False, False])\n",
      "torch.Size([64, 37])\n",
      "tensor([[-3.7887, -3.7887, -3.7887,  ..., -2.8908, -3.7887, -3.7887],\n",
      "        [-4.8526, -4.8526, -4.8526,  ..., -2.7777, -4.8526, -4.8526],\n",
      "        [-3.6637, -2.9874, -3.6637,  ..., -3.6637, -3.6637, -3.6637],\n",
      "        ...,\n",
      "        [-3.3470, -4.0330, -4.0330,  ..., -3.2856, -4.0330, -4.0330],\n",
      "        [-4.2386, -4.2386, -4.2386,  ..., -2.0682, -4.2386, -4.2386],\n",
      "        [-3.6841, -3.3080, -3.6841,  ..., -2.8282, -3.6841, -3.6841]])\n",
      "tensor([False,  True, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False,  True, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False,  True,\n",
      "        False, False, False, False, False, False,  True, False, False, False,\n",
      "        False, False,  True,  True, False, False, False, False,  True, False,\n",
      "        False,  True, False, False, False, False, False, False,  True, False,\n",
      "        False, False, False,  True])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 37])\n",
      "tensor([[-3.8470, -1.8390, -3.8470,  ..., -3.8470, -3.8470, -3.8470],\n",
      "        [-3.3535, -3.6704, -3.6704,  ..., -3.6363, -3.6704, -3.6704],\n",
      "        [-3.8530, -3.1564, -3.8530,  ..., -2.6238, -3.8530, -3.8530],\n",
      "        ...,\n",
      "        [-3.9105, -2.8268, -3.9105,  ..., -3.9105, -3.9105, -3.9105],\n",
      "        [-4.3640, -2.0078, -4.3640,  ..., -4.3640, -4.3640, -4.3640],\n",
      "        [-3.8693, -1.8964, -3.8693,  ..., -2.9599, -3.8693, -3.8693]])\n",
      "tensor([ True, False, False, False, False, False, False,  True, False,  True,\n",
      "        False, False, False, False, False, False, False,  True, False, False,\n",
      "        False, False, False, False,  True, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False, False, False, False, False,\n",
      "        False, False, False,  True, False, False, False, False, False, False,\n",
      "        False, False,  True, False])\n",
      "torch.Size([64, 37])\n",
      "tensor([[-3.7765, -3.2802, -3.7765,  ..., -2.8888, -3.7765, -3.7765],\n",
      "        [-3.6516, -3.1317, -3.6516,  ..., -3.5545, -3.6516, -3.6516],\n",
      "        [-3.6787, -2.9197, -3.6787,  ..., -3.1903, -3.6787, -3.6787],\n",
      "        ...,\n",
      "        [-3.6575, -3.1961, -3.6575,  ..., -3.6575, -3.6575, -3.6575],\n",
      "        [-3.6592, -3.6592, -3.6592,  ..., -3.0011, -3.6592, -3.6592],\n",
      "        [-3.6866, -2.6894, -3.6866,  ..., -3.6866, -3.6866, -3.6866]])\n",
      "tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False,  True, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False,  True,  True, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False])\n",
      "torch.Size([64, 37])\n",
      "tensor([[-3.6624, -3.6935, -3.6935,  ..., -3.6935, -3.6935, -3.6935],\n",
      "        [-3.7550, -3.1004, -3.7550,  ..., -3.7550, -3.7550, -3.7550],\n",
      "        [-3.6922, -2.8116, -3.6922,  ..., -3.6922, -3.6922, -3.6922],\n",
      "        ...,\n",
      "        [-3.7434, -2.7187, -3.7434,  ..., -3.7434, -3.7434, -3.7434],\n",
      "        [-3.7761, -3.7761, -3.7761,  ..., -2.5039, -3.7761, -3.7761],\n",
      "        [-3.9071, -3.6258, -3.9071,  ..., -3.9071, -3.9071, -3.9071]])\n",
      "tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "         True, False, False, False,  True, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False,  True, False, False,\n",
      "         True, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False])\n",
      "torch.Size([64, 37])\n",
      "tensor([[-3.6296, -3.5745, -3.6296,  ..., -3.5228, -3.6296, -3.6296],\n",
      "        [-3.7003, -3.3356, -3.7003,  ..., -2.9283, -3.7003, -3.7003],\n",
      "        [-3.6426, -3.3581, -3.6426,  ..., -3.3466, -3.6426, -3.6426],\n",
      "        ...,\n",
      "        [-4.2879, -4.2879, -4.2879,  ..., -3.5139, -4.2879, -4.2879],\n",
      "        [-3.6773, -2.9889, -3.6773,  ..., -3.1380, -3.6773, -3.6773],\n",
      "        [-3.6772, -3.5006, -3.6772,  ..., -3.4164, -3.6772, -3.6772]])\n",
      "tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False,  True, False, False, False,  True, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False,  True, False, False, False,  True, False, False, False,\n",
      "        False, False,  True, False,  True, False, False, False, False, False,\n",
      "        False, False, False, False])\n",
      "torch.Size([64, 37])\n",
      "tensor([[-3.6490, -3.5383, -3.6490,  ..., -3.6406, -3.6490, -3.6490],\n",
      "        [-3.6740, -3.6740, -3.6740,  ..., -3.1087, -3.6740, -3.6740],\n",
      "        [-3.6849, -2.5952, -3.6849,  ..., -3.0598, -3.6849, -3.6849],\n",
      "        ...,\n",
      "        [-4.0512, -2.0496, -4.0512,  ..., -4.0512, -4.0512, -4.0512],\n",
      "        [-3.6362, -3.6362, -3.6362,  ..., -3.6362, -3.6362, -3.6362],\n",
      "        [-3.7726, -3.6718, -3.7726,  ..., -2.8734, -3.7726, -3.7726]])\n",
      "tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False,  True, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False,  True, False, False, False, False, False,  True, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False,  True, False, False, False, False, False, False,\n",
      "        False, False, False, False])\n",
      "torch.Size([19, 37])\n",
      "tensor([[-3.6555, -3.3108, -3.6555, -3.6555, -3.6555, -3.6555, -3.6555, -3.6555,\n",
      "         -3.6555, -3.6555, -3.6555, -3.6555, -3.0035, -3.6555, -3.6555, -3.6555,\n",
      "         -3.6555, -3.6555, -3.6555, -3.6555, -3.6555, -3.6555, -3.6555, -3.6555,\n",
      "         -3.6555, -3.6555, -3.6555, -3.6555, -3.6555, -3.6555, -3.6555, -3.6555,\n",
      "         -3.6555, -3.6555, -3.3507, -3.6555, -3.6555],\n",
      "        [-3.6632, -3.0221, -3.6632, -3.6632, -3.6632, -3.6632, -3.6632, -3.6632,\n",
      "         -3.6632, -3.6632, -3.6632, -3.4708, -3.6632, -3.6632, -3.6632, -3.6632,\n",
      "         -3.6632, -3.0339, -3.6632, -3.6632, -3.6632, -3.6632, -3.6632, -3.6632,\n",
      "         -3.6632, -3.6632, -3.6632, -3.6632, -3.6632, -3.6632, -3.6632, -3.6632,\n",
      "         -3.6632, -3.6632, -3.6632, -3.6632, -3.6632],\n",
      "        [-3.8031, -2.4934, -3.8031, -3.8031, -3.8031, -3.8031, -3.8031, -3.8031,\n",
      "         -3.8031, -3.8031, -3.5937, -2.5826, -3.8031, -3.8031, -3.5502, -3.8031,\n",
      "         -3.8031, -2.9918, -3.8031, -3.8031, -3.8031, -3.8031, -3.8031, -3.8031,\n",
      "         -3.8031, -3.8031, -3.1223, -3.8031, -3.8031, -3.8031, -3.8031, -3.8031,\n",
      "         -3.8031, -3.8031, -3.8031, -3.8031, -3.8031],\n",
      "        [-3.4902, -4.0281, -4.0281, -4.0281, -4.0281, -4.0281, -4.0281, -4.0281,\n",
      "         -4.0281, -4.0281, -3.3732, -4.0281, -4.0281, -4.0281, -4.0281, -4.0281,\n",
      "         -4.0281, -3.7735, -4.0281, -4.0281, -4.0281, -4.0281, -4.0281, -1.8533,\n",
      "         -1.8120, -4.0281, -3.2155, -4.0281, -4.0281, -4.0281, -4.0281, -4.0281,\n",
      "         -4.0281, -4.0281, -4.0281, -4.0281, -4.0281],\n",
      "        [-3.6821, -2.5316, -3.6821, -3.6821, -3.6821, -3.6821, -3.6821, -3.6821,\n",
      "         -3.6821, -3.6821, -3.6821, -3.6821, -3.5531, -3.6821, -3.6004, -3.6821,\n",
      "         -3.6821, -3.6821, -3.6821, -3.6821, -3.6821, -3.6821, -3.6821, -3.3832,\n",
      "         -3.6821, -3.6821, -3.6821, -3.6821, -3.6821, -3.6821, -3.6821, -3.6821,\n",
      "         -3.6821, -3.6821, -3.6821, -3.6821, -3.6821],\n",
      "        [-3.7705, -2.7788, -3.7705, -3.7705, -3.7705, -3.7705, -3.7705, -3.7705,\n",
      "         -3.7705, -3.7705, -3.6713, -3.7705, -3.7705, -3.7705, -3.7705, -3.7705,\n",
      "         -3.7705, -2.8163, -3.7705, -3.7705, -3.7705, -3.7705, -3.7705, -3.2775,\n",
      "         -3.3268, -3.7705, -2.7376, -3.7705, -3.7705, -3.7705, -3.7705, -3.7705,\n",
      "         -3.7705, -3.7705, -3.7705, -3.7705, -3.7705],\n",
      "        [-3.7713, -2.7013, -3.7713, -3.7713, -3.7713, -3.7713, -3.7713, -3.7713,\n",
      "         -3.7713, -3.7713, -3.7713, -3.7713, -3.7713, -3.7713, -3.7713, -3.7713,\n",
      "         -3.7713, -3.7713, -3.7713, -3.7713, -3.7713, -3.7713, -3.7713, -2.0937,\n",
      "         -3.7713, -3.7713, -3.6166, -3.7713, -3.7713, -3.7713, -3.7713, -3.7713,\n",
      "         -3.7713, -3.7713, -3.7713, -3.7713, -3.7713],\n",
      "        [-4.0107, -3.6365, -4.0107, -4.0107, -4.0107, -4.0107, -4.0107, -4.0107,\n",
      "         -4.0107, -4.0107, -4.0107, -4.0107, -1.9083, -4.0107, -1.9187, -4.0107,\n",
      "         -4.0107, -4.0107, -3.9915, -3.7040, -4.0107, -4.0107, -4.0107, -4.0107,\n",
      "         -4.0107, -4.0107, -4.0107, -4.0107, -4.0107, -4.0107, -4.0107, -4.0107,\n",
      "         -4.0107, -4.0107, -2.6077, -4.0107, -4.0107],\n",
      "        [-3.7524, -3.2825, -3.7524, -3.7524, -3.7524, -3.7524, -3.7524, -2.8623,\n",
      "         -3.7524, -3.7524, -3.7524, -3.7524, -3.4055, -3.7524, -3.4709, -3.7524,\n",
      "         -3.7524, -3.7524, -3.7524, -3.4678, -3.7524, -3.7524, -3.6235, -3.7524,\n",
      "         -3.7524, -3.7524, -3.7524, -3.7524, -3.7524, -3.7524, -3.0929, -3.7524,\n",
      "         -3.7524, -3.7524, -2.8572, -3.7524, -3.7524],\n",
      "        [-4.0769, -3.8078, -4.0769, -4.0769, -4.0769, -4.0769, -4.0769, -4.0769,\n",
      "         -4.0769, -4.0769, -4.0769, -3.9858, -2.4057, -4.0769, -2.8151, -4.0769,\n",
      "         -4.0769, -4.0769, -3.5993, -2.3189, -4.0769, -4.0769, -2.6640, -4.0769,\n",
      "         -4.0769, -4.0769, -4.0769, -4.0769, -4.0769, -4.0769, -3.7985, -4.0769,\n",
      "         -4.0769, -4.0769, -2.1504, -4.0769, -4.0769],\n",
      "        [-3.6853, -3.6853, -3.6853, -3.6853, -3.6853, -3.6853, -3.6853, -3.6853,\n",
      "         -3.6853, -3.6853, -3.6853, -3.6853, -2.9602, -3.6853, -2.9417, -3.6853,\n",
      "         -3.6853, -3.6853, -3.5025, -3.3411, -3.6853, -3.6853, -3.6853, -3.6853,\n",
      "         -3.6853, -3.6853, -3.6853, -3.6853, -3.6853, -3.6853, -3.6853, -3.6853,\n",
      "         -3.6853, -3.6853, -3.6105, -3.6853, -3.6853],\n",
      "        [-3.8253, -1.7034, -3.8253, -3.8253, -3.8253, -3.8253, -3.8253, -3.8253,\n",
      "         -3.8253, -3.8253, -3.8253, -3.8253, -3.8253, -3.8253, -3.8253, -3.8253,\n",
      "         -3.8253, -3.8253, -3.8253, -3.8253, -3.8253, -3.8253, -3.8253, -3.1261,\n",
      "         -3.8253, -3.8253, -3.4287, -3.8253, -3.8253, -3.8253, -3.8253, -3.8253,\n",
      "         -3.8253, -3.8253, -3.8253, -3.8253, -3.8253],\n",
      "        [-3.2526, -3.8170, -3.8170, -3.8170, -3.8170, -3.8170, -3.8170, -3.8170,\n",
      "         -3.8170, -3.8170, -3.8170, -3.8170, -3.8170, -3.8170, -3.8170, -3.8170,\n",
      "         -3.8170, -3.8170, -3.8170, -3.5328, -3.8170, -3.8170, -3.8170, -2.0452,\n",
      "         -2.5827, -3.8170, -3.8170, -3.8170, -3.8170, -3.8170, -3.8170, -3.8170,\n",
      "         -3.8170, -3.8170, -3.7545, -3.8170, -3.8170],\n",
      "        [-3.6660, -2.8446, -3.6660, -3.6660, -3.6660, -3.6660, -3.6660, -3.6660,\n",
      "         -3.6660, -3.6660, -3.6660, -3.6660, -3.6660, -3.6660, -3.6660, -3.6660,\n",
      "         -3.6660, -3.6660, -3.6660, -3.6660, -3.6660, -3.6660, -3.6660, -3.2027,\n",
      "         -3.6660, -3.6660, -3.6660, -3.6660, -3.6660, -3.6660, -3.6660, -3.6660,\n",
      "         -3.6660, -3.6660, -3.4559, -3.6660, -3.6660],\n",
      "        [-4.0271, -3.5483, -4.0271, -4.0271, -4.0271, -4.0271, -4.0271, -3.7176,\n",
      "         -4.0271, -4.0271, -4.0271, -4.0271, -3.3397, -4.0271, -3.1719, -4.0271,\n",
      "         -4.0271, -4.0271, -3.7580, -1.9712, -4.0271, -4.0271, -3.4415, -4.0271,\n",
      "         -4.0271, -4.0271, -4.0271, -4.0271, -4.0271, -4.0271, -2.7018, -4.0271,\n",
      "         -4.0271, -4.0271, -2.2191, -4.0271, -4.0271],\n",
      "        [-3.7909, -3.7491, -3.7909, -3.7909, -3.7909, -3.7909, -3.7909, -3.7909,\n",
      "         -3.7909, -3.7909, -3.7909, -3.7909, -3.0071, -3.7909, -2.8800, -3.7909,\n",
      "         -3.7909, -3.7909, -3.4833, -2.9319, -3.7909, -3.7909, -3.3715, -3.7909,\n",
      "         -3.7909, -3.7909, -3.7909, -3.7909, -3.7909, -3.7909, -3.0470, -3.7909,\n",
      "         -3.7909, -3.7909, -2.9885, -3.7909, -3.7909],\n",
      "        [-3.6869, -2.8142, -3.6869, -3.6869, -3.6869, -3.6869, -3.6869, -3.6869,\n",
      "         -3.6869, -3.6869, -3.6869, -3.6869, -3.6050, -3.6869, -3.4845, -3.6869,\n",
      "         -3.6869, -3.1554, -3.6869, -3.6869, -3.6869, -3.6869, -3.6869, -3.6869,\n",
      "         -3.6869, -3.6869, -3.6869, -3.6869, -3.6869, -3.6869, -3.6869, -3.6869,\n",
      "         -3.6869, -3.6869, -3.2708, -3.6869, -3.6869],\n",
      "        [-3.5651, -3.7149, -3.7149, -3.7149, -3.7149, -3.7149, -3.7149, -3.7149,\n",
      "         -3.7149, -3.7149, -3.7149, -3.7149, -3.4131, -3.7149, -3.6542, -3.7149,\n",
      "         -3.7149, -3.7149, -3.7149, -2.4942, -3.7149, -3.7149, -3.7149, -3.5326,\n",
      "         -3.6576, -3.7149, -3.7149, -3.7149, -3.7149, -3.7149, -3.4531, -3.7149,\n",
      "         -3.7149, -3.7126, -3.2916, -3.7149, -3.7149],\n",
      "        [-4.0462, -4.0462, -4.0462, -4.0462, -4.0462, -4.0462, -4.0462, -1.9326,\n",
      "         -4.0462, -4.0462, -4.0462, -4.0462, -2.9534, -4.0462, -3.6303, -4.0462,\n",
      "         -4.0462, -4.0462, -4.0462, -3.0345, -4.0462, -4.0462, -2.3320, -4.0462,\n",
      "         -4.0462, -4.0462, -4.0462, -4.0462, -4.0462, -4.0462, -2.5008, -4.0462,\n",
      "         -4.0462, -4.0462, -3.7022, -4.0462, -4.0462]])\n",
      "tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in valid_loader:\n",
    "        out = model(images.float())\n",
    "        print(out.shape)\n",
    "        print(out)\n",
    "        print(torch.max(out,1)[1]==labels)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b052a46a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
