{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de83c0f6",
   "metadata": {},
   "source": [
    "We shall use a Linear SVM classifier on the dataset r1 and compare the results with the CNN based models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "97471391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage as ski\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038990ad",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6b03c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PetDatasetSVM(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir):\n",
    "        self.img_annotations = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_annotations)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img_path = os.path.join(self.img_dir,self.img_annotations.iloc[idx,0])\n",
    "        image = ski.io.imread(img_path)/255\n",
    "        image = ski.transform.rescale(image,0.85)    # resize to 255 pix a side\n",
    "        image = image[:,:,:3]  # dropping the alpha channel if any\n",
    "        image = image.reshape(-1) # reshaping the image data into a 1d vector\n",
    "        class_label = self.img_annotations.iloc[idx,2]-1      # the -1 is coz labels are expected from 0 to C-1\n",
    "            \n",
    "        return image, class_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "befa4a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_r1 = PetDatasetSVM('annotations_aug/annotations_train_r1.csv','img_augmented_processed/')\n",
    "valid = PetDatasetSVM('annotations_aug/annotations_valid.csv','img_augmented_processed/')\n",
    "test = PetDatasetSVM('annotations_aug/annotations_test.csv','img_augmented_processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be796d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = len(train_r1)\n",
    "train_r1_loader = DataLoader(train_r3,batch_size=all_data)\n",
    "train_images, train_labels = next(iter(train_r1_loader))\n",
    "train_images, train_labels = train_images.numpy(), train_labels.numpy() # Dataloader outputs a tensor, converting to numpy ndarray\n",
    "\n",
    "\n",
    "valid_loader = DataLoader(valid,batch_size=len(valid))\n",
    "valid_images, valid_labels = next(iter(valid_loader))\n",
    "valid_images, valid_labels = valid_images.numpy(), valid_labels.numpy()\n",
    "\n",
    "test_loader = DataLoader(test,batch_size=len(test))\n",
    "test_images, test_labels = next(iter(test_loader))\n",
    "test_images, test_labels = test_images.numpy(), test_labels.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6aae70f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of training batch (images): (7102, 195075)\n",
      "shape of training batch (labels): (7102,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('shape of training batch (images): {}'.format(train_images.shape))\n",
    "print('shape of training batch (labels): {}'.format(train_labels.shape))\n",
    "type(train_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f455d3ea",
   "metadata": {},
   "source": [
    "# SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79a30842",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_scale = StandardScaler()\n",
    "train_images = feature_scale.fit_transform(train_images)      # setting mean to 0, variance to 1\n",
    "valid_images = feature_scale.fit_transform(valid_images) \n",
    "test_images = feature_scale.fit_transform(test_images) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46dd0d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_trainer = SVC()\n",
    "svm_trainer.fit(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a13b9cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on a random training batch:0.40673828125\n"
     ]
    }
   ],
   "source": [
    "train_r1_loader2 = DataLoader(train_r3,batch_size=2048, shuffle=True)\n",
    "train_images_test, train_labels_test = next(iter(train_r1_loader2))\n",
    "train_images_test, train_labels_test = train_images_test.numpy(), train_labels_test.numpy()\n",
    "\n",
    "train_predictions = svm_trainer.predict(feature_scale.fit_transform(train_images_test))\n",
    "print('Accuracy on a random training batch:{}'.format(accuracy_score(train_labels_test,train_predictions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "255caf21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on a random training batch:0.40771484375\n",
      "Time taken:2202.200286626816\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "train_images_test, train_labels_test = next(iter(train_r1_loader2))\n",
    "train_images_test, train_labels_test = train_images_test.numpy(), train_labels_test.numpy()\n",
    "\n",
    "train_predictions = svm_trainer.predict(feature_scale.fit_transform(train_images_test))\n",
    "print('Accuracy on a random training batch:{}'.format(accuracy_score(train_labels_test,train_predictions)))\n",
    "\n",
    "end = time.time()\n",
    "print('Time taken:{}'.format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2117413e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the validation set:0.07377598926894702\n",
      "Time taken:1592.6651875972748\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "valid_predictions = svm_trainer.predict(valid_imagesss)\n",
    "print('Accuracvalid_imagesmagesmagese validation set:{}'.format(accuracy_score(valid_labels,valid_predictions)))\n",
    "\n",
    "end = time.time()\n",
    "print('Time taken:{}'.format(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ada04c",
   "metadata": {},
   "source": [
    "This is much worse than the CNN based models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a30178",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
